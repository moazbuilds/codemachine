{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"<p> CodeMachine CLI is an autonomous multi-agent platform that works locally on your computer, turning specifications into production-ready code.</p> <p> <code>npm i -g codemachine</code> </p> <p> </p> <p> \u2728 CodeMachine Built Itself </p> <p> 90% of this entire codebase was generated by CodeMachine from a single specification file.   This isn't a demo\u2014it's proof. CodeMachine engine orchestrated its own architecture, planning, implementation, and testing\u2014creating a massively scalable codebase ready for continuous updates and improvements. </p>"},{"location":"#what-is-codemachine","title":"What is CodeMachine?","text":"<p>CodeMachine is a CLI-native orchestration platform that transforms specification files and contextual inputs into production-ready code through coordinated multi-agent workflows. Specialized AI agents operate in hierarchical and parallel configurations with the ability for bidirectional communication, enabling runtime-adaptable methodologies that dynamically adjust to project requirements without framework modifications.</p> <p>Why CodeMachine?</p> <ul> <li>Customizable, End-to-End Workflows: Architect sophisticated orchestration pipelines for any scale, from executing simple scripts to managing multi-day, complex development cycles.</li> <li>Strategic Multi-Agent Collaboration: Leverage a heterogeneous multi-agent system by assigning specialized models to specific tasks\u2014for instance, using Gemini for planning, Claude for implementation, and another model for code review.</li> <li>Massively Parallel Execution: Achieve significantly accelerated output by deploying sub-agents that operate simultaneously on different components of a task.</li> <li>Persistent, Long-Running Orchestration: Execute workflows for extended durations\u2014hours or even days\u2014to autonomously accomplish complex, long-term development goals.</li> </ul>"},{"location":"#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"#installing-and-running-codemachine-cli","title":"Installing and running CodeMachine CLI","text":"<p>First, install the command-line tool globally via npm: <pre><code>npm install -g codemachine\n</code></pre></p> <p>Then, simply run <code>codemachine</code> in your project directory to get started. <pre><code>codemachine\n</code></pre></p>"},{"location":"#initializing-a-project","title":"Initializing a Project","text":"<p>CodeMachine initializes a <code>.codemachine/</code> workspace. To start add your specs to the <code>inputs/specifications.md</code> file, then run <code>/start</code> and watch the magic happen, CodeMachine will:  *   Architect a complete system blueprint from your requirements.  *   Formulate detailed, step-by-step execution plans.  *   Engineer clean, production-grade code for every component.  *   Generate essential automation for testing and deployment.  *   Integrate rigorous validation checks across every phase of execution.</p>"},{"location":"#supported-ai-engines","title":"Supported AI Engines","text":"<p>CodeMachine requires at least one CLI-based AI engine to handle the primary roles of planning and writing code, and is designed to orchestrate multiple engines to collaborate within a single workflow. The table below shows the current status of supported engines and their platform compatibility.</p> CLI Engine Status Windows macOS Linux Codex CLI \u2705 Supported \u26a0\ufe0f \u2705 \u2705 Claude Code \u2705 Supported \u2705 \u2705 \u2705 CCR (Claude Code Router) \u2705 Supported \u2705 \u2705 \u2705 OpenCode CLI \u2705 Supported \u2705 \u2705 \u2705 Cursor CLI \u2705 Supported \u274c \u2705 \u2705 Gemini CLI \ud83d\udea7 Coming Soon \u2705 \u2705 \u2705 Qwen Coder \ud83d\udea7 Coming Soon \u2705 \u2705 \u2705 <p> \u2705 Fully Supported  |  \u26a0\ufe0f Not Officially Supported  |  \u274c Not Available </p>"},{"location":"#opencode-cli-integration","title":"OpenCode CLI Integration","text":"<p>OpenCode ships as a first-class engine. Install the CLI with <code>npm i -g opencode-ai@latest</code> (or <code>brew install opencode</code>, <code>scoop install extras/opencode</code>, <code>choco install opencode</code>) and then:</p> <ul> <li><code>codemachine opencode run \"build hello world\"</code> streams JSON-formatted OpenCode output through CodeMachine\u2019s log markers.</li> <li>Workflow steps can force OpenCode with <code>codemachine step &lt;agent&gt; --engine opencode --model anthropic/claude-3.7-sonnet</code>.</li> <li>Guardrail environment defaults (overridable) are applied automatically: <code>OPENCODE_PERMISSION={\"edit\":\"allow\",\"webfetch\":\"allow\",\"bash\":{\"*\":\"allow\"}}</code>, <code>OPENCODE_DISABLE_LSP_DOWNLOAD=1</code>, <code>OPENCODE_DISABLE_DEFAULT_PLUGINS=1</code>, and <code>OPENCODE_CONFIG_DIR=$HOME/.codemachine/opencode</code>.</li> <li>Set <code>CODEMACHINE_SKIP_OPENCODE=1</code> for dry-run workflows or <code>CODEMACHINE_PLAIN_LOGS=1</code> when you need ANSI-free logs.</li> </ul>"},{"location":"#production-validation","title":"Production Validation:","text":"<p>CodeMachine has been battle-tested on the Sustaina Platform a full-stack ESG compliance system spanning 7 microservices, 500+ files, and 60,000+ lines of code across Python, TypeScript, React, FastAPI, and NestJS.</p> Services Generated 7 microservices (AI/ML + CRUD APIs) Codebase Scale ~500 files, 60K+ Line of code Tech Stack React 18, FastAPI, NestJS, PostgreSQL, MongoDB, Redis, Kubernetes Time to MVP ~8 hours of autonomous orchestration"},{"location":"#codemachine-vs-regular-ai-agents","title":"CodeMachine vs Regular AI Agents","text":"<p>We conducted a real-world comparison by monitoring development work on a project of identical scope and complexity using the most powerful AI agent tools (Claude Code, Cursor, Copilot) with manual orchestration and human review, versus CodeMachine's autonomous multi-agent orchestration.</p> Aspect Regular AI Agents(Manual Orchestration + Human Review) CodeMachine(Autonomous Orchestration) Architecture Planning 4-6 hours of manual prompting Automated (30 min) Service Implementation 140-200 hours (7 services \u00d7 20-30h each)Manual prompting, context switching Parallel execution (5 hours) Integration &amp; Testing 30-50 hoursManual coordination, debugging Automated validation (2 hours) Deployment Setup 8-12 hoursScripts, configs, orchestration Auto-generated (30 min) Code Consistency Inconsistent patterns across servicesDifferent coding styles per session Unified architecture &amp; patternsConsistent across all components Quality Control Manual review requiredErrors compound over time Built-in validation at each stepAutomated sanity checks Context Retention Lost between sessionsRepeated explanations needed Full project context maintainedCross-service awareness Total Developer Time ~200-300 hours ~8 hours Efficiency Gain Baseline 25-37\u00d7 faster <p>Real-world comparison: One developer manually prompting AI coding assistants vs CodeMachine's autonomous multi-agent orchestration</p> <p> Want to see how CodeMachine built this?   Explore the complete case study showing the detailed path CodeMachine took to create this project\u2014every step, decision, and workflow tracked from specification to production. </p> <p> \ud83d\udcca View Complete Case Study &amp; Development Track \u2192 </p>"},{"location":"#documentation","title":"\ud83d\udcda Documentation","text":"<p>Getting Started - Prerequisites &amp; Installation - Quick Start Guide   - Writing Your Specification   - Running the Workflow - How CodeMachine Works</p> <p>Core Concepts - Agents in CodeMachine   - Main Agents   - Sub Agents   - Modules   - Dynamic Agent Generation - Communication Patterns   - Sequential Execution   - Parent-Child Delegation - Context Management   - File-Based Memory   - Session Memory</p> <p>CLI Usage - CLI Overview   - Global Options   - Interactive Mode - Workflow Commands   - Start Command   - Template Selection - Development Commands   - Run Command   - Step Execution - Authentication   - Login   - Logout - Advanced Topics   - Engine-Specific Commands</p> <p>Creating Custom Workflows - Workflow Templates   - Template Structure   - Step Resolution Functions   - Override Options - Configuring Agents   - Main Agents   - Sub Agents   - Workflow Modules - Engine &amp; Model Selection   - Available Engines   - Model Options   - Reasoning Levels - Advanced Patterns   - Loop Behaviors   - Fallback Handling   - Mixed Engine Workflows</p> <p>Writing Specifications - Specification Schema   - Essential Requirements   - Advanced Specifications</p>"},{"location":"#contributors","title":"\ud83d\ude4f Contributors","text":"<p>Special thanks to the following contributors who have helped make CodeMachine better:</p> <ul> <li> <p>Bahy Ali - Architect of the original workflow system and core orchestration concepts. His deep expertise and guidance were instrumental in shaping CodeMachine's foundation.</p> </li> <li> <p>Adinda Praditya - Added CCR (Claude Code Router) engine support, removing a major limitation by enabling users to leverage AI capabilities beyond subscription-based services.</p> </li> <li> <p>SoyHub - Enhanced the UI system and contributed innovative ideas during brainstorming sessions that helped strengthen CodeMachine's capabilities.</p> </li> <li> <p>TheMightyDman - Added OpenCode CLI engine integration, which brings support for multiple AI providers (Anthropic, OpenAI, Google, and more) to CodeMachine. An enthusiastic and active contributor to the project.</p> </li> </ul>"},{"location":"architecture/","title":"Overview","text":"<p>CodeMachine is an orchestration platform that lets you achieve any complex coding objective through customizable agent workflows. Whether you need to refactor a legacy system, migrate between frameworks, generate documentation, or create entirely new applications, the platform provides the infrastructure to coordinate specialized AI agents for any coding task.</p> <p>CodeMachine's default workflow template enables you to transform specifications directly into production-ready codebases, providing immediate value out of the box. Beyond this foundation, the platform's extensible architecture empowers you to craft custom workflows tailored to your unique development pipeline and requirements.</p>"},{"location":"architecture/#who-its-for","title":"Who It's For","text":"<p>CodeMachine is built for developers, tech leads, and engineering teams who want to accelerate development without sacrificing code quality or architectural consistency.</p>"},{"location":"architecture/#what-you-can-achieve","title":"What You Can Achieve","text":""},{"location":"architecture/#for-individual-developers","title":"For Individual Developers","text":"<ul> <li>Full applications generated - Complete codebases ready for production</li> <li>Zero boilerplate writing - Focus on features, not setup</li> </ul>"},{"location":"architecture/#for-engineering-teams","title":"For Engineering Teams","text":"<ul> <li>Orchestrate any workflow - From simple tasks to complex migrations</li> <li>Shared agent context - File-based or memory context preservation</li> <li>Grow without limits - Same tool for 500 or 10,000 file projects</li> </ul>"},{"location":"architecture/#quick-start","title":"Quick Start","text":""},{"location":"architecture/#prerequisites","title":"Prerequisites","text":"<p>Before starting, ensure your environment meets these requirements:</p> Requirement Minimum Version Notes Node.js 20.10.0 Required for running CodeMachine CLI npm 9.0.0 Package manager (pnpm also supported) AI Engine CLI Latest At least one: Codex CLI, Claude Code CLI, Cursor CLI, CCR CLI, or OpenCode CLI"},{"location":"architecture/#get-your-first-project-generated","title":"Get your first project generated","text":"<pre><code># Install CodeMachine\nnpm install -g codemachine\n</code></pre> <pre><code># Run CodeMachine inside your project folder\ncd my-awesome-project\ncodemachine\n</code></pre> <p>Write a sample specifications: <pre><code>Create a small, single-user to-do application that MUST support create, read, update, and delete operations.\n</code></pre></p> <pre><code># Run the workflow inside CodeMachine shell\n/start\n</code></pre> <p>Note: You can use <code>--spec &lt;path&gt;</code> to specify a custom specification file path (Default: <code>.codemachine/inputs/specifications.md</code>)</p>"},{"location":"architecture/#how-codemachine-works","title":"How CodeMachine Works","text":"<p>CodeMachine's core innovation is breaking down complex coding workflows into small, manageable tasks that AI agents can effectively handle. Instead of overwhelming a single agent with an entire project specification\u2014which often fails due to context limitations and complexity\u2014the platform uses workflow templates to decompose work into discrete, achievable steps.</p> <p>The workflow template establishes a sequence of steps, with each step representing a main agent. These main agents can invoke sub-agents through prompt-driven commands to complete various tasks. Main agents have full capability to write code and orchestrate complex operations, and can utilize sub-agents as needed - though both main and sub-agents are capable of handling any type coding of task.</p> <p> </p>"},{"location":"architecture/#agents-in-codemachine","title":"Agents in CodeMachine","text":""},{"location":"architecture/#overview_1","title":"Overview","text":"<p>CodeMachine's workflow system is built around three fundamental components: Main Agents, Sub Agents, and Modules. These components work together to execute complex, multi-step workflows with specialized capabilities and intelligent orchestration.</p>"},{"location":"architecture/#main-agents","title":"Main Agents","text":"<p>Main agents serve as the primary execution steps in a workflow. Each main agent represents a discrete phase or task in your development process.</p>"},{"location":"architecture/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Workflow Steps: A main agent is a step in the workflow execution</li> <li>Orchestration Capability: Can delegate tasks to and coordinate sub agents</li> <li>Module Integration: Can leverage specialized modules for advanced workflow behaviors</li> </ul>"},{"location":"architecture/#sub-agents","title":"Sub Agents","text":"<p>Sub agents are specialized agents that operate under the coordination of main agents. They provide focused expertise and can be dynamically invoked based on workflow requirements.</p>"},{"location":"architecture/#key-characteristics_1","title":"Key Characteristics","text":"<ul> <li>Orchestrated Execution: Called and managed by main agents</li> <li>Specialized Focus: Designed for specific tasks or domains</li> <li>Same Structure: Share the same core properties as main agents</li> </ul>"},{"location":"architecture/#modules","title":"Modules","text":"<p>Modules are specialized workflow components that are implemented as agents but trigger specific execution behaviors.</p>"},{"location":"architecture/#what-modules-enable","title":"What Modules Enable","text":"<ul> <li>Conditional Logic: Trigger specific agents based on runtime conditions</li> <li>Loop Constructs: Implement iterative workflows (e.g., back loop steps)</li> <li>Dynamic Routing: Direct execution flow based on intermediate results</li> </ul>"},{"location":"architecture/#agent-properties","title":"Agent Properties","text":"<p>Every agent (both main and sub) is defined by four core properties:</p>"},{"location":"architecture/#1-identity","title":"1. Identity","text":"<ul> <li>Unique ID: A distinct identifier for the agent</li> <li>Descriptive Name: A human-readable name that conveys the agent's role</li> </ul>"},{"location":"architecture/#2-purpose","title":"2. Purpose","text":"<p>A focused description that clearly defines the agent's role and responsibilities within the workflow.</p>"},{"location":"architecture/#3-prompt","title":"3. Prompt","text":"<p>Path to a prompt template file that defines the agent's behavior, instructions, and operational context. This template guides the AI's actions when executing as this agent.</p>"},{"location":"architecture/#4-ai-profile","title":"4. AI Profile","text":"<p>Configuration settings that control the AI engine: - model: Specifies which AI model to use for this agent - modelReasoningEffort: Controls the reasoning depth and execution approach</p>"},{"location":"architecture/#dynamic-agent-generation","title":"Dynamic Agent Generation","text":"<p>Main agents are defined using carefully engineered prompts with built-in guard rails to ensure consistent and reliable performance. In contrast, sub-agent prompts can be optionally generated by the main agents themselves. For example, an agent builder main agent can create specialized sub-agents on-demand, crafting their prompts with project-specific backgrounds and instructions tailored to the exact requirements of the current task. This dynamic prompt generation capability allows the system to adapt and create perfectly suited sub-agents for each unique project context.</p> <p> </p>"},{"location":"architecture/#agent-communication-patterns","title":"Agent Communication Patterns","text":""},{"location":"architecture/#1-sequential-hierarchical-communication","title":"1. Sequential Hierarchical Communication","text":"<p>Pattern: Main Agents Sequential Execution</p>"},{"location":"architecture/#overview_2","title":"Overview","text":"<p>This pattern enables a linear workflow where multiple main agents execute in a predetermined sequence, with each agent completing its task before triggering the next agent in the chain.</p> <p> </p>"},{"location":"architecture/#what-you-can-achieve_1","title":"What You Can Achieve","text":"<ul> <li>Phased Development Workflows: Perfect for projects requiring distinct phases (e.g., design \u2192 implementation \u2192 testing)</li> <li>Dependency Management: Ensures tasks with strict dependencies are executed in the correct order</li> <li>Progressive Refinement: Each agent can build upon the output of the previous one, refining and enhancing the codebase</li> <li>Checkpoint Validation: Natural breakpoints between agents allow for validation and quality checks</li> </ul>"},{"location":"architecture/#2-parent-child-agent-to-agent-communication","title":"2. Parent-Child Agent-to-Agent Communication","text":"<p>Pattern: Main Agent with SubAgent Delegation</p>"},{"location":"architecture/#overview_3","title":"Overview","text":"<p>The main agent acts as an orchestrator, delegating specific tasks to specialized SubAgents while maintaining overall control and context management.</p>"},{"location":"architecture/#implementation-examples","title":"Implementation Examples","text":""},{"location":"architecture/#a-basic-parent-child-call","title":"a. Basic Parent-Child Call","text":"<ul> <li>Main agent identifies a specialized task (e.g., frontend component generation)</li> <li>Delegates to appropriate SubAgent with specific context</li> <li>Receives results and integrates them into the broader workflow</li> <li>Achievement: Modular task execution with specialized expertise</li> </ul>"},{"location":"architecture/#b-multi-subagent-coordination-parallel-or-sequential","title":"b. Multi-SubAgent Coordination (Parallel or Sequential)","text":"<ul> <li>Main agent analyzes project requirements</li> <li>Spawns multiple SubAgents for different components (Frontend, Backend, DevOps)</li> <li>Can execute SubAgents in parallel for independent tasks or sequentially for dependent ones</li> <li>Main agent acts as evaluator, ensuring consistency across all outputs</li> <li>Achievement: Rapid development through parallel execution while maintaining architectural coherence</li> </ul>"},{"location":"architecture/#c-orchestrated-evaluation-workflow-context-manager-pattern","title":"c. Orchestrated Evaluation Workflow (Context Manager Pattern)","text":"<ul> <li>Main agent initiates parallel execution (green-colored agents in diagram)</li> <li>Multiple SubAgents work simultaneously on their domains</li> <li>Upon completion, a specialized evaluator agent (yellow-colored) is called sequentially</li> <li>Evaluator reviews all parallel outputs for quality, consistency, and integration readiness</li> <li>Achievement: Quality assurance through peer review while maximizing throughput</li> </ul>"},{"location":"architecture/#what-you-can-achieve_2","title":"What You Can Achieve","text":"<ul> <li>Dynamic Task Distribution: Automatically scale agent deployment based on project complexity</li> <li>Specialized Expertise: Each SubAgent can be optimized for specific technologies or frameworks</li> <li>Bidirectional Communication: SubAgents can request clarification or additional context from the parent</li> <li>Adaptive Workflows: Runtime adjustment of agent configuration based on intermediate results</li> <li>Comprehensive Testing: QA SubAgent can validate work from all other agents before final delivery</li> <li>Resource Optimization: Parallel execution for independent tasks, sequential for dependent operations</li> </ul>"},{"location":"architecture/#advanced-capabilities","title":"Advanced Capabilities","text":"<ul> <li>Context Preservation: Main agent maintains global project context while SubAgents focus on local optimization</li> <li>Error Recovery: If a SubAgent fails, the main agent can retry with modified parameters or delegate to an alternative agent</li> <li>Progressive Enhancement: Start with basic implementation, then layer additional SubAgents for optimization, security, and performance</li> <li>Cross-Domain Integration: Coordinate between different technology stacks through specialized SubAgents</li> </ul>"},{"location":"architecture/#agent-context-management-types","title":"Agent Context Management Types","text":""},{"location":"architecture/#1-file-based-main-agent-memory","title":"1. File-Based Main Agent Memory","text":""},{"location":"architecture/#overview_4","title":"Overview","text":"<p>File-based memory enables persistent context sharing between agents through structured file systems, allowing complex workflows to maintain state and share information across multiple agent executions.</p>"},{"location":"architecture/#a-standard-workflow-memory-json-based","title":"a. Standard Workflow Memory (JSON-Based)","text":""},{"location":"architecture/#how-it-works","title":"How It Works","text":"<ul> <li>After each agent completes its task, a structured memory file (JSON) is automatically created</li> <li>Contains execution metadata, outputs, decisions, and key context points</li> <li>Subsequent agents can query this memory repository to retrieve relevant context</li> <li>Memory files are indexed and searchable for efficient context retrieval</li> </ul>"},{"location":"architecture/#what-you-can-achieve_3","title":"What You Can Achieve","text":"<ul> <li>Historical Context Preservation: Maintain complete execution history across agent runs</li> <li>Intelligent Context Retrieval: Agents can search previous executions for similar patterns or solutions</li> <li>Prompt-Driven Context Loading: Dynamically load specific context based on current task requirements</li> <li>Debugging &amp; Auditing: Complete trace of all agent decisions and outputs for troubleshooting</li> </ul>"},{"location":"architecture/#b-markdown-file-pipeline-sequential-context-transfer","title":"b. Markdown File Pipeline (Sequential Context Transfer)","text":""},{"location":"architecture/#how-it-works_1","title":"How It Works","text":"<ul> <li>Main Agent A generates comprehensive markdown documentation (A.md)</li> <li>Main Agent B reads A.md directly through prompt placeholders</li> <li>Agent B processes and enhances, creating B.md with accumulated knowledge</li> <li>Chain continues with each agent building upon previous documentation</li> </ul>"},{"location":"architecture/#what-you-can-achieve_4","title":"What You Can Achieve","text":"<ul> <li>Progressive Documentation: Each agent adds layers of detail and refinement</li> <li>Structured Knowledge Transfer: Markdown format ensures human-readable context</li> <li>Template-Based Generation: Use placeholders in prompts for dynamic content injection</li> <li>Version Control Friendly: Markdown files integrate seamlessly with Git workflows</li> </ul>"},{"location":"architecture/#2-orchestrator-agent-session-memory","title":"2. Orchestrator Agent Session Memory","text":""},{"location":"architecture/#overview_5","title":"Overview","text":"<p>In parent-child communication patterns, the orchestrator (main agent) maintains centralized session memory, enabling sophisticated coordination and context management across multiple SubAgents.</p>"},{"location":"architecture/#how-it-works_2","title":"How It Works","text":"<ul> <li>Main Agent initiates SubAgent with specific task and context</li> <li>SubAgent processes task within its specialized domain</li> <li>Session memory returns to Main Agent with:</li> <li>Task results</li> <li>Learned patterns</li> <li>Decisions made</li> <li>Potential issues or recommendations</li> <li>Main Agent integrates session memory into global context</li> <li>Continues execution with enriched understanding</li> </ul>"},{"location":"architecture/#what-you-can-achieve_5","title":"What You Can Achieve","text":""},{"location":"architecture/#centralized-intelligence","title":"Centralized Intelligence","text":"<ul> <li>Main agent becomes progressively smarter as it accumulates SubAgent insights</li> <li>Cross-domain learning: Frontend discoveries can inform Backend decisions</li> <li>Pattern recognition across multiple SubAgent executions</li> </ul>"},{"location":"architecture/#dynamic-adaptation","title":"Dynamic Adaptation","text":"<ul> <li>Adjust subsequent SubAgent parameters based on accumulated session memory</li> <li>Redistribute tasks if certain approaches prove unsuccessful</li> <li>Real-time workflow optimization based on intermediate results</li> </ul>"},{"location":"architecture/#context-propagation","title":"Context Propagation","text":"<ul> <li>Selective context sharing: Only relevant portions sent to each SubAgent</li> <li>Prevents context pollution while maintaining necessary information</li> <li>Efficient memory usage through intelligent filtering</li> </ul>"},{"location":"architecture/#quality-assurance","title":"Quality Assurance","text":"<ul> <li>Main agent can validate SubAgent outputs against accumulated context</li> <li>Detect inconsistencies or conflicts between different SubAgent results</li> <li>Ensure architectural coherence across all components</li> </ul>"},{"location":"architecture/#advanced-capabilities_1","title":"Advanced Capabilities","text":""},{"location":"architecture/#bidirectional-learning","title":"Bidirectional Learning","text":"<ul> <li>SubAgents can query main agent for clarification</li> <li>Main agent updates global strategy based on SubAgent feedback</li> <li>Continuous refinement loop throughout execution</li> </ul>"},{"location":"architecture/#parallel-session-merging","title":"Parallel Session Merging","text":"<ul> <li>When multiple SubAgents run in parallel, session memories merge intelligently</li> <li>Conflict resolution strategies for contradictory findings</li> <li>Consensus building across multiple agent perspectives</li> </ul>"},{"location":"architecture/#checkpoint-recovery","title":"Checkpoint &amp; Recovery","text":"<ul> <li>Session memory enables resumption from any point</li> <li>Failed SubAgent tasks can be retried with adjusted parameters</li> <li>Partial results preserved even in failure scenarios</li> </ul>"},{"location":"cli-reference/","title":"CLI Reference","text":"<p>Complete command-line interface reference for CodeMachine.</p>"},{"location":"cli-reference/#overview","title":"Overview","text":"<p>CodeMachine provides a command-line interface for managing workflows, executing agents, and configuring your development environment.</p> <p>Basic Usage: <pre><code>codemachine [command] [options]\n</code></pre></p> <p>Global Options:</p> Option Description Default <code>-d, --dir &lt;path&gt;</code> Target workspace directory <code>process.cwd()</code> <code>--spec &lt;path&gt;</code> Path to planning specification file <code>.codemachine/inputs/specifications.md</code> <code>-h, --help</code> Display help for command - <p>Package Binary: - Entry point: <code>./dist/index.js</code> - Command name: <code>codemachine</code></p>"},{"location":"cli-reference/#interactive-mode","title":"Interactive Mode","text":"<p>When no command is provided, CodeMachine starts in interactive session mode.</p> <p>Usage: <pre><code>codemachine\ncodemachine -d /path/to/workspace\n</code></pre></p> <p>Features: - Interactive shell session with keyboard controls - Real-time workflow execution - Template selection menu - Authentication management - Onboarding for new users</p> <p>Session Flow: 1. CLI checks working directory (<code>-d</code> option or current directory) 2. Syncs configuration for all registered engines 3. Bootstraps <code>.codemachine/</code> folder if it doesn't exist 4. Enters interactive shell with main menu</p> <p>Workspace Structure: <pre><code>.codemachine/\n\u251c\u2500\u2500 inputs/\n\u2502   \u2514\u2500\u2500 specifications.md     # Default spec file\n\u251c\u2500\u2500 template.json              # Selected template\n\u2514\u2500\u2500 [engine-specific-configs]\n</code></pre></p>"},{"location":"cli-reference/#workflow-commands","title":"Workflow Commands","text":"<p>Commands for managing and executing workflows.</p>"},{"location":"cli-reference/#start","title":"<code>start</code>","text":"<p>Run the workflow queue until completion in non-interactive mode.</p> <p>Syntax: <pre><code>codemachine start [options]\n</code></pre></p> <p>Options:</p> Option Description Default <code>--spec &lt;path&gt;</code> Path to the planning specification file <code>.codemachine/inputs/specifications.md</code> <p>Behavior: - Executes workflow queue sequentially - Runs in non-interactive mode (no user prompts) - Exits with status code on completion</p> <p>Exit Codes: - <code>0</code> - Workflow completed successfully - <code>1</code> - Workflow failed</p> <p>Output Messages: - Success: <code>\u2713 Workflow completed successfully</code> - Error: <code>\u2717 Workflow failed: [error message]</code></p> <p>Examples: <pre><code># Run workflow with default spec\ncodemachine start\n\n# Run workflow with custom spec\ncodemachine start --spec ./custom/planning.md\n\n# Run in specific directory\ncodemachine -d /path/to/project start\n\n# Custom directory and spec\ncodemachine -d /path/to/project start --spec ./specs/feature.md\n</code></pre></p> <p>Use Cases: - CI/CD pipeline automation - Batch workflow execution - Automated code generation scripts - Testing workflows</p> <p>Technical Details: - Source: <code>src/cli/commands/start.command.ts</code> - Non-blocking execution - Error handling with detailed messages</p>"},{"location":"cli-reference/#templates","title":"<code>templates</code>","text":"<p>List and select workflow templates interactively.</p> <p>Syntax: <pre><code>codemachine templates\n</code></pre></p> <p>Arguments: None</p> <p>Options: None</p> <p>Behavior: - Lists all available workflow templates from <code>templates/workflows/</code> - Displays interactive selection menu - Auto-regenerates agents folder when template changes - Saves selection to <code>.codemachine/template.json</code></p> <p>Template Format: - Files ending with <code>.workflow.js</code> - Located in <code>templates/workflows/</code> directory - Export workflow configuration and agent definitions</p> <p>Examples: <pre><code># List and select template interactively\ncodemachine templates\n\n# Use in specific workspace\ncodemachine -d /path/to/project templates\n</code></pre></p> <p>Template Storage: - Selection saved to: <code>.codemachine/template.json</code> - Default template: <code>templates/workflows/codemachine.workflow.js</code> - Example template: <code>templates/workflows/_example.workflow.js</code></p> <p>Use Cases: - Switch between different workflow types - Initialize new projects with specific templates - Customize agent configurations per project</p> <p>Technical Details: - Source: <code>src/cli/commands/templates.command.ts</code> - Supports both interactive and programmatic selection - Triggers agent folder regeneration on template change</p>"},{"location":"cli-reference/#development-commands","title":"Development Commands","text":"<p>Commands for executing agents and workflow steps during development.</p>"},{"location":"cli-reference/#run","title":"<code>run</code>","text":"<p>Execute single agents or orchestrate multiple agents with the unified run command.</p> <p>Syntax: <pre><code>codemachine run &lt;script&gt;\ncodemachine &lt;engine-name&gt; run &lt;script&gt;\n</code></pre></p> <p>Arguments:</p> Argument Required Description <code>&lt;script&gt;</code> Yes Agent execution script with optional orchestration syntax <p>Options:</p> Option Description Default <code>--model &lt;model&gt;</code> Model to use (overrides agent config) Agent's configured model <code>-d, --dir &lt;directory&gt;</code> Working directory <code>process.cwd()</code> <p>Script Syntax:</p> <p>The <code>&lt;script&gt;</code> parameter supports several formats:</p> <ol> <li> <p>Simple agent execution: <pre><code>\"agent-id 'prompt'\"\n</code></pre></p> </li> <li> <p>Enhanced syntax with parameters: <pre><code>\"agent-id[input:file1.md;file2.md,tail:100] 'prompt'\"\n</code></pre></p> </li> </ol> <p>Available parameters:    - <code>input:&lt;file&gt;</code> or <code>input:&lt;file1&gt;;&lt;file2&gt;</code> - Include file content(s) in agent context    - <code>tail:&lt;number&gt;</code> - Limit file content to last N lines</p> <ol> <li> <p>Parallel execution (using <code>&amp;</code>): <pre><code>\"agent1 'prompt1' &amp; agent2 'prompt2' &amp; agent3 'prompt3'\"\n</code></pre></p> </li> <li> <p>Sequential execution (using <code>&amp;&amp;</code>): <pre><code>\"agent1 'prompt1' &amp;&amp; agent2 'prompt2' &amp;&amp; agent3 'prompt3'\"\n</code></pre></p> </li> <li> <p>Mixed execution: <pre><code>\"agent1 'prompt1' &amp;&amp; agent2 'prompt2' &amp; agent3 'prompt3'\"\n</code></pre></p> </li> </ol> <p>Engine-Specific Commands: Each registered engine can be invoked directly: <pre><code>codemachine claude run \"agent 'prompt'\"\ncodemachine codex run \"agent 'prompt'\"\ncodemachine cursor run \"agent 'prompt'\"\n</code></pre></p> <p>Examples:</p> <pre><code># Simple single agent execution\ncodemachine run \"code-generator 'Build login feature'\"\n\n# Agent with input files\ncodemachine run \"system-analyst[input:.codemachine/agents/system-analyst.md,tail:100] 'analyze architecture'\"\n\n# Multiple input files without prompt\ncodemachine run \"arch-writer[input:file1.md;file2.md;file3.md]\"\n\n# Parallel orchestration\ncodemachine run \"frontend[tail:50] 'UI' &amp; backend[tail:50] 'API' &amp; db[tail:30] 'schema'\"\n\n# Sequential orchestration\ncodemachine run \"db 'Setup schema' &amp;&amp; backend 'Create models' &amp;&amp; api 'Build endpoints'\"\n\n# Mixed orchestration\ncodemachine run \"db[tail:50] 'setup' &amp;&amp; frontend[input:design.md,tail:100] &amp; backend[input:api-spec.md,tail:100]\"\n\n# With specific engine\ncodemachine claude run \"code-generator 'Create a login component'\"\n\n# Override model\ncodemachine run \"code-generator 'Create component'\" --model gpt-4\n\n# In specific workspace\ncodemachine -d /my/project run \"my-agent 'Generate tests'\"\n</code></pre> <p>Agent Resolution: 1. Searches <code>config/main.agents.js</code> 2. Searches <code>config/sub.agents.js</code> 3. Throws error if agent ID not found</p> <p>Execution Behavior: - <code>&amp;</code> operator: Agents execute in parallel - <code>&amp;&amp;</code> operator: Agents execute sequentially (waits for previous completion) - Mixed: Evaluates left-to-right with operator precedence - Enhanced syntax allows including file contents and limiting output</p> <p>Use Cases: - Single agent execution for quick tasks - Multi-agent orchestration for complex workflows - Including specification files in agent context - Parallel feature development across multiple agents - Sequential pipeline execution (design \u2192 implement \u2192 test)</p> <p>Technical Details: - Source: <code>src/cli/commands/run.command.ts</code> - Uses <code>CoordinatorService</code> for execution - Parses scripts via <code>CoordinatorParser</code> - Replaces both old <code>agent</code> and <code>orchestrate</code> commands - Supports enhanced syntax not available in legacy commands</p> <p>Migration from Legacy Commands:</p> <p>If you were using the old <code>agent</code> command: <pre><code># Old\ncodemachine agent code-generator \"Create login\"\n\n# New\ncodemachine run \"code-generator 'Create login'\"\n</code></pre></p> <p>If you were using the old <code>orchestrate</code> command: <pre><code># Old\ncodemachine orchestrate \"frontend 'UI' &amp; backend 'API'\"\n\n# New (same syntax, different command)\ncodemachine run \"frontend 'UI' &amp; backend 'API'\"\n</code></pre></p>"},{"location":"cli-reference/#step","title":"<code>step</code>","text":"<p>Execute a single workflow step using an agent from the main agents configuration.</p> <p>Syntax: <pre><code>codemachine step [options] &lt;id&gt; [prompt...]\n</code></pre></p> <p>Arguments:</p> Argument Required Description <code>&lt;id&gt;</code> Yes Agent ID from <code>config/main.agents.js</code> <code>[prompt...]</code> No Optional additional prompt to append to agent's main prompt <p>Options:</p> Option Description Default <code>--model &lt;model&gt;</code> Model to use Resolved from priority chain <code>--engine &lt;engine&gt;</code> Engine to use Resolved from priority chain <code>--reasoning &lt;level&gt;</code> Reasoning effort: <code>low</code>, <code>medium</code>, or <code>high</code> Agent's config or engine default <p>Option Resolution Priority:</p> <p>Engine Resolution: 1. CLI <code>--engine</code> override 2. Agent config <code>engine</code> property 3. First authenticated engine 4. Default engine (first registered)</p> <p>Model Resolution: 1. CLI <code>--model</code> override 2. Agent config <code>model</code> property 3. Engine's default model</p> <p>Reasoning Resolution: 1. CLI <code>--reasoning</code> override 2. Agent config <code>modelReasoningEffort</code> 3. Engine default reasoning level</p> <p>Behavior: - Executes main workflow agent in isolated step - Requires engine authentication - Displays formatted output with spinning indicators - Stores last 2000 characters in memory</p> <p>Examples: <pre><code># Execute step with agent's default config\ncodemachine step planner\n\n# Execute with additional prompt\ncodemachine step planner \"Focus on microservices architecture\"\n\n# Override engine\ncodemachine step planner --engine claude\n\n# Override model\ncodemachine step planner --model gpt-4-turbo\n\n# Override reasoning level\ncodemachine step planner --reasoning high\n\n# Combine multiple overrides\ncodemachine step planner \"Design API\" --engine codex --model gpt-4 --reasoning high\n\n# Execute in specific workspace\ncodemachine -d /project step implementation \"Add error handling\"\n</code></pre></p> <p>Authentication: - Requires authenticated engine - Error message if engine not authenticated:   <pre><code>Engine '[engine-name]' requires authentication.\nRun: codemachine auth login\n</code></pre></p> <p>Agent Source: - Only searches <code>config/main.agents.js</code> - Does not search <code>config/sub.agents.js</code> - Throws error if agent not found in main agents</p> <p>Use Cases: - Test individual workflow steps - Debug main agents in isolation - Experiment with different models/engines - Run specific workflow phases manually</p> <p>Technical Details: - Source: <code>src/cli/commands/step.command.ts</code> - Output formatting with typewriter effect - Memory preservation for session context - Authentication validation before execution</p>"},{"location":"cli-reference/#configuration-commands","title":"Configuration Commands","text":"<p>Commands for managing authentication and system configuration.</p>"},{"location":"cli-reference/#auth","title":"<code>auth</code>","text":"<p>Authentication management for AI engine providers.</p> <p>Subcommands: - <code>auth login</code> - Authenticate with a provider - <code>auth logout</code> - Logout from a provider</p>"},{"location":"cli-reference/#auth-login","title":"<code>auth login</code>","text":"<p>Authenticate with CodeMachine AI engine services.</p> <p>Syntax: <pre><code>codemachine auth login\n</code></pre></p> <p>Arguments: None</p> <p>Options: None</p> <p>Behavior: - Displays interactive provider selection menu - Lists all registered engine providers - Calls provider's authentication system - Stores credentials securely per engine</p> <p>Provider Selection: Interactive menu shows: - Provider name - Authentication status (authenticated/not authenticated)</p> <p>Already Authenticated: If already authenticated, displays: <pre><code>Already authenticated with [Provider].\nUse `codemachine auth logout` to sign out.\n</code></pre></p> <p>Examples: <pre><code># Interactive provider login\ncodemachine auth login\n\n# Returns to menu after authentication\n# Can authenticate multiple providers\n</code></pre></p> <p>Authentication Flow: 1. Display registered providers 2. User selects provider 3. Provider-specific auth process (API key, OAuth, etc.) 4. Credentials stored in engine config 5. Confirmation message</p> <p>Use Cases: - Initial setup of AI engines - Re-authenticate expired sessions - Switch between different provider accounts - Enable new engines in workspace</p> <p>Technical Details: - Source: <code>src/cli/commands/auth.command.ts</code> - Providers loaded from engine registry - Engine-specific authentication handlers - Secure credential storage</p>"},{"location":"cli-reference/#auth-logout","title":"<code>auth logout</code>","text":"<p>Logout from CodeMachine AI engine services.</p> <p>Syntax: <pre><code>codemachine auth logout\n</code></pre></p> <p>Arguments: None</p> <p>Options: None</p> <p>Behavior: - Displays interactive provider selection menu - Shows only authenticated providers - Clears authentication for selected provider - Updates engine configuration</p> <p>Logout Confirmation: <pre><code>Signed out from [Provider].\nNext action will be `login`.\n</code></pre></p> <p>Examples: <pre><code># Interactive provider logout\ncodemachine auth logout\n\n# Select provider from menu\n# Credentials cleared\n</code></pre></p> <p>Use Cases: - Switch provider accounts - Remove expired credentials - Security: clear credentials when sharing machine - Testing unauthenticated flows</p> <p>Technical Details: - Source: <code>src/cli/commands/auth.command.ts</code> - Clears provider-specific credentials - Updates configuration files - Preserves other provider authentications</p>"},{"location":"cli-reference/#utility-commands","title":"Utility Commands","text":"<p>Utility and informational commands.</p>"},{"location":"cli-reference/#version","title":"<code>version</code>","text":"<p>Display the CodeMachine CLI version.</p> <p>Syntax: <pre><code>codemachine version\ncodemachine --version\ncodemachine -V\n</code></pre></p> <p>Arguments: None</p> <p>Options: None</p> <p>Output: <pre><code>CodeMachine v[version]\n</code></pre></p> <p>Examples: <pre><code>codemachine version\n# Output: CodeMachine v1.0.0\n</code></pre></p> <p>Use Cases: - Verify installation - Check for updates - Bug reporting - Compatibility checks</p>"},{"location":"cli-reference/#advanced-topics","title":"Advanced Topics","text":""},{"location":"cli-reference/#engine-specific-commands","title":"Engine-Specific Commands","text":"<p>CodeMachine dynamically registers engine-specific command variants for each registered AI engine.</p> <p>Pattern: <pre><code>codemachine &lt;engine-name&gt; run &lt;script&gt;\n</code></pre></p> <p>Examples: <pre><code># Claude-specific agent execution\ncodemachine claude run \"my-agent 'Generate code'\"\n\n# Codex-specific agent execution\ncodemachine codex run \"my-agent 'Generate code'\"\n\n# Cursor engine variant\ncodemachine cursor run \"my-agent 'Generate code'\"\n\n# OpenCode engine variant\ncodemachine opencode run \"build hello world\"\n</code></pre></p> <p>Behavior: - Same options and arguments as main <code>run</code> command - Forces execution with specific engine - Useful for engine comparison and testing</p> <p>Dynamic Registration: - Commands registered automatically at startup - Based on engines in engine registry - Each engine gets its own subcommand namespace</p>"},{"location":"cli-reference/#opencode-environment-guardrails","title":"OpenCode Environment Guardrails","text":"<p>The OpenCode provider needs explicit permission defaults to stay non-interactive. When you run <code>codemachine opencode ...</code> or <code>--engine opencode</code>, the CLI injects (unless already set):</p> <ul> <li><code>OPENCODE_PERMISSION={\"edit\":\"allow\",\"webfetch\":\"allow\",\"bash\":{\"*\":\"allow\"}}</code></li> <li><code>OPENCODE_DISABLE_LSP_DOWNLOAD=1</code> and <code>OPENCODE_DISABLE_DEFAULT_PLUGINS=1</code></li> <li><code>OPENCODE_CONFIG_DIR=$HOME/.codemachine/opencode</code> (can be overridden)</li> </ul> <p>You can also set <code>CODEMACHINE_SKIP_OPENCODE=1</code> to dry-run pipelines without launching the CLI, or <code>CODEMACHINE_PLAIN_LOGS=1</code> to strip ANSI markers in log exports.</p>"},{"location":"cli-reference/#startup-and-initialization","title":"Startup and Initialization","text":"<p>CLI Startup Flow:</p> <ol> <li>Parse Global Options</li> <li>Check for <code>-d/--dir</code> to set working directory</li> <li> <p>Check for <code>--spec</code> to override default specification path</p> </li> <li> <p>Pre-Action Hook</p> </li> <li>Sync configuration for all registered engines</li> <li> <p>Validate workspace structure</p> </li> <li> <p>Bootstrap Workspace</p> </li> <li> <p>If <code>.codemachine/</code> doesn't exist:</p> <ul> <li>Create directory structure</li> <li>Initialize with default template</li> <li>Create default spec file</li> </ul> </li> <li> <p>Register Commands</p> </li> <li>Register all standard commands</li> <li> <p>Dynamically register engine-specific commands</p> </li> <li> <p>Execute Command or Enter Interactive Mode</p> </li> <li>If command provided: execute and exit</li> <li>If no command: enter interactive session shell</li> </ol> <p>Default Workspace Bootstrap: <pre><code>.codemachine/\n\u251c\u2500\u2500 inputs/\n\u2502   \u2514\u2500\u2500 specifications.md     # Created with template\n\u251c\u2500\u2500 template.json              # Set to default template\n\u2514\u2500\u2500 [engine configs]           # Created on first auth\n</code></pre></p>"},{"location":"cli-reference/#quick-reference","title":"Quick Reference","text":"<p>Most Common Commands:</p> <pre><code># Start interactive session\ncodemachine\n\n# Run workflow\ncodemachine start\n\n# Select template\ncodemachine templates\n\n# Authenticate\ncodemachine auth login\n\n# Execute agent or orchestrate\ncodemachine run \"&lt;agent-id&gt; 'prompt'\"\n\n# Execute workflow step\ncodemachine step &lt;id&gt;\n\n# Check version\ncodemachine version\n</code></pre> <p>With Options:</p> <pre><code># Set workspace\ncodemachine -d /path/to/project\n\n# Custom spec\ncodemachine start --spec ./specs/custom.md\n\n# Override model\ncodemachine step planner --model gpt-4\n\n# Override engine and reasoning\ncodemachine step planner --engine claude --reasoning high\n</code></pre>"},{"location":"customizing-workflows/","title":"Customizing Workflows","text":"<p>Complete guide to customizing CodeMachine workflows, agents, and configurations.</p>"},{"location":"customizing-workflows/#overview","title":"Overview","text":"<p>CodeMachine workflows are highly customizable through configuration files and workflow templates. This guide covers everything you need to create, customize, and optimize workflows for your specific use cases.</p> <p>What You Can Customize: - Agent definitions and roles - Workflow step sequences - AI engines and models per step - Loop and trigger behaviors - Fallback handling - Execution policies</p>"},{"location":"customizing-workflows/#configuration-files","title":"Configuration Files","text":"<p>All configuration files are located in the <code>config/</code> directory at the project root.</p>"},{"location":"customizing-workflows/#directory-structure","title":"Directory Structure","text":"<pre><code>config/\n\u251c\u2500\u2500 main.agents.js      # Primary workflow agents\n\u251c\u2500\u2500 sub.agents.js       # Sub-agents for orchestration\n\u251c\u2500\u2500 modules.js          # Workflow modules (loop/trigger behaviors)\n\u251c\u2500\u2500 placeholders.js     # Path placeholder definitions\n\u2514\u2500\u2500 package.json        # Config package metadata\n</code></pre>"},{"location":"customizing-workflows/#main-agents-configuration","title":"Main Agents Configuration","text":"<p>File: <code>config/main.agents.js</code></p> <p>Main agents represent the primary steps in your workflow execution. These are the agents that appear in workflow templates and execute sequentially.</p>"},{"location":"customizing-workflows/#structure","title":"Structure","text":"<pre><code>export default {\n  agents: [\n    {\n      id: 'agent-identifier',           // Required: Unique ID\n      name: 'Human Readable Name',      // Required: Display name\n      description: 'Agent role...',     // Required: Purpose description\n      promptPath: 'path/to/prompt.md'   // Required: Prompt template path\n    }\n  ]\n};\n</code></pre>"},{"location":"customizing-workflows/#real-example-codemachine-main-agents","title":"Real Example: CodeMachine Main Agents","text":""},{"location":"customizing-workflows/#export-default-agents-id-arch-agent-name-architecture-agent-description-defines-the-system-architecture-and-technical-decisions-promptpath-promptstemplatescodemachineagents01-architecture-agentmd-id-plan-agent-name-plan-agent-description-generates-comprehensive-development-plans-promptpath-promptstemplatescodemachineagents02-planning-agentmd-id-task-breakdown-name-task-breakdown-agent-description-structures-work-into-discrete-executable-tasks-json-format-promptpath-promptstemplatescodemachineagents03-task-breakdown-agentmd","title":"<pre><code>export default {\n  agents: [\n    {\n      id: 'arch-agent',\n      name: 'Architecture Agent',\n      description: 'Defines the system architecture and technical decisions',\n      promptPath: 'prompts/templates/codemachine/agents/01-architecture-agent.md'\n    },\n    {\n      id: 'plan-agent',\n      name: 'Plan Agent',\n      description: 'Generates comprehensive development plans',\n      promptPath: 'prompts/templates/codemachine/agents/02-planning-agent.md'\n    },\n    {\n      id: 'task-breakdown',\n      name: 'Task Breakdown Agent',\n      description: 'Structures work into discrete, executable tasks (JSON format)',\n      promptPath: 'prompts/templates/codemachine/agents/03-task-breakdown-agent.md'\n    }\n  ]\n};\n</code></pre>","text":""},{"location":"customizing-workflows/#sub-agents-configuration","title":"Sub-Agents Configuration","text":"<p>File: <code>config/sub.agents.js</code></p> <p>Sub-agents are specialized agents that can be invoked by main agents for specific tasks. They're useful for domain-specific expertise and parallel execution patterns.</p>"},{"location":"customizing-workflows/#structure_1","title":"Structure","text":"<pre><code>export default {\n  agents: [\n    {\n      id: 'sub-agent-id',\n      name: 'Display Name',\n      description: 'Specialized role description',\n      promptPath: 'path/to/prompt.md'\n    }\n  ]\n};\n</code></pre>"},{"location":"customizing-workflows/#real-example-codemachine-sub-agents","title":"Real Example: CodeMachine Sub-Agents","text":"<pre><code>export default {\n  agents: [\n    {\n      id: 'uxui-designer',\n      name: 'UX/UI Designer',\n      description: 'Specializes in user experience and interface design',\n      promptPath: 'prompts/templates/codemachine/sub-agents/uxui-designer.md'\n    },\n    {\n      id: 'frontend-dev',\n      name: 'Frontend Developer',\n      description: 'Frontend development specialist',\n      promptPath: 'prompts/templates/codemachine/sub-agents/frontend-developer.md'\n    },\n    {\n      id: 'backend-dev',\n      name: 'Backend Developer',\n      description: 'Backend development specialist',\n      promptPath: 'prompts/templates/codemachine/sub-agents/backend-developer.md'\n    },\n    {\n      id: 'solution-architect',\n      name: 'Solution Architect',\n      description: 'Solution architecture specialist',\n      promptPath: 'prompts/templates/codemachine/sub-agents/solution-architect.md'\n    },\n    {\n      id: 'technical-writer',\n      name: 'Technical Writer',\n      description: 'Documentation specialist',\n      promptPath: 'prompts/templates/codemachine/sub-agents/technical-writer.md'\n    }\n  ]\n};\n</code></pre>"},{"location":"customizing-workflows/#when-to-use-sub-agents","title":"When to Use Sub-Agents","text":"<ul> <li>Specialized expertise: Domain-specific tasks (frontend, backend, QA)</li> <li>Parallel execution: Multiple sub-agents working simultaneously</li> <li>Dynamic orchestration: Main agent decides which sub-agents to invoke</li> <li>Context isolation: Each sub-agent works in its own context</li> </ul>"},{"location":"customizing-workflows/#workflow-modules-configuration","title":"Workflow Modules Configuration","text":"<p>File: <code>config/modules.js</code></p> <p>Modules are special agents that trigger specific workflow behaviors like loops and conditional agent calls.</p>"},{"location":"customizing-workflows/#module-types","title":"Module Types","text":""},{"location":"customizing-workflows/#1-loop-behavior","title":"1. Loop Behavior","text":"<p>Allows workflows to repeat previous steps based on validation results.</p> <p>Structure: <pre><code>{\n  id: 'module-id',\n  name: 'Module Name',\n  promptPath: 'path/to/prompt.md',\n  behavior: {\n    type: 'loop',\n    action: 'stepBack',\n    steps: number,              // How many steps to go back\n    maxIterations: number,      // Maximum loop count\n    skip: ['agent-id']          // Agent IDs to skip when looping\n  }\n}\n</code></pre></p> <p>Real Example: <pre><code>{\n  id: 'check-task',\n  name: 'Check Task',\n  promptPath: 'prompts/templates/codemachine/workflows/task-verification-workflow.md',\n  behavior: {\n    type: 'loop',\n    action: 'stepBack',\n    steps: 6,                   // Go back 6 steps\n    maxIterations: 20,          // Maximum 20 iterations\n    skip: ['runtime-prep']      // Skip runtime-prep when looping\n  }\n}\n</code></pre></p> <p>Use Cases: - Task validation with retry logic - Code review loops until approval - Iterative refinement workflows - Quality gates with re-execution</p>"},{"location":"customizing-workflows/#2-trigger-behavior","title":"2. Trigger Behavior","text":"<p>Allows workflows to dynamically call specific agents based on runtime conditions.</p> <p>Structure: <pre><code>{\n  id: 'module-id',\n  name: 'Module Name',\n  promptPath: 'path/to/prompt.md',\n  behavior: {\n    type: 'trigger',\n    action: 'mainAgentCall',\n    triggerAgentId: 'default-agent-id'  // Default agent to trigger\n  }\n}\n</code></pre></p> <p>Real Example: <pre><code>{\n  id: 'iteration-checker',\n  name: 'Iteration Checker',\n  promptPath: 'prompts/templates/codemachine/workflows/iteration-verification-workflow.md',\n  behavior: {\n    type: 'trigger',\n    action: 'mainAgentCall',\n    triggerAgentId: 'context-manager'   // Default trigger\n  }\n}\n</code></pre></p> <p>Use Cases: - Conditional workflow branching - Dynamic agent selection - Context-aware routing - Adaptive workflows</p>"},{"location":"customizing-workflows/#path-placeholders-configuration","title":"Path Placeholders Configuration","text":"<p>File: <code>config/placeholders.js</code></p> <p>Defines reusable path placeholders for prompt templates and workflow artifacts.</p>"},{"location":"customizing-workflows/#user-directory-paths","title":"User Directory Paths","text":"<p>Paths within the user's <code>.codemachine/</code> workspace:</p> <pre><code>export const userDir = {\n  specifications: '.codemachine/inputs/specifications.md',\n  architecture: '.codemachine/artifacts/architecture/*.md',\n  architecture_manifest_json: '.codemachine/artifacts/architecture/architecture_manifest.json',\n  plan: '.codemachine/artifacts/plan/*.md',\n  plan_manifest_json: '.codemachine/artifacts/plan/plan_manifest.json',\n  plan_fallback: '.codemachine/prompts/plan_fallback.md',\n  tasks: '.codemachine/artifacts/tasks.json',\n  all_tasks_json: '.codemachine/artifacts/tasks/*.json',\n  task_fallback: '.codemachine/prompts/task_fallback.md',\n  context: '.codemachine/prompts/context.md',\n  code_fallback: '.codemachine/prompts/code_fallback.md'\n};\n</code></pre>"},{"location":"customizing-workflows/#package-directory-paths","title":"Package Directory Paths","text":"<p>Paths within the CodeMachine package:</p> <pre><code>export const packageDir = {\n  orchestration_guide: 'prompts/orchestration/guide.md',\n  arch_output_format: 'prompts/templates/codemachine/output-formats/architecture-output.md',\n  plan_output_format: 'prompts/templates/codemachine/output-formats/planning-output.md',\n  task_output_format: 'prompts/templates/codemachine/output-formats/task-breakdown-output.md',\n  context_output_format: 'prompts/templates/codemachine/output-formats/context-output.md',\n  task_validation_output_format: 'prompts/templates/codemachine/output-formats/task-validation-output.md'\n};\n</code></pre>"},{"location":"customizing-workflows/#using-placeholders-in-prompts","title":"Using Placeholders in Prompts","text":"<p>Placeholders are automatically resolved when prompts are loaded:</p> <pre><code>&lt;!-- In your prompt template --&gt;\nRead the specifications from: {{userDir.specifications}}\nFollow the format in: {{packageDir.plan_output_format}}\n</code></pre>"},{"location":"customizing-workflows/#workflow-templates","title":"Workflow Templates","text":"<p>Location: <code>templates/workflows/</code></p> <p>Workflow templates define the sequence of agent steps and their configurations.</p>"},{"location":"customizing-workflows/#template-structure","title":"Template Structure","text":"<pre><code>export default {\n  name: 'Workflow Name',      // Required: Display name\n\n  steps: [                    // Required: Array of workflow steps\n    // Step definitions...\n  ],\n\n  subAgentIds: [              // Optional: Available sub-agents\n    'sub-agent-id'\n  ]\n};\n</code></pre>"},{"location":"customizing-workflows/#step-resolution-functions","title":"Step Resolution Functions","text":""},{"location":"customizing-workflows/#resolvestepagentid-overrides","title":"<code>resolveStep(agentId, overrides?)</code>","text":"<p>Resolves a single agent step with optional configuration overrides.</p> <p>Basic Usage: <pre><code>resolveStep('arch-agent')\n</code></pre></p> <p>With Overrides: <pre><code>resolveStep('plan-agent', {\n  executeOnce: true,\n  engine: 'claude',\n  model: 'opus',\n  modelReasoningEffort: 'high',\n  agentName: 'Senior Architect',\n  promptPath: './custom/prompt.md',\n  notCompletedFallback: 'plan-fallback'\n})\n</code></pre></p>"},{"location":"customizing-workflows/#resolvemodulemoduleid-overrides","title":"<code>resolveModule(moduleId, overrides?)</code>","text":"<p>Resolves a workflow module with behavior configuration.</p> <p>Usage: <pre><code>resolveModule('check-task', {\n  loopSteps: 6,\n  loopMaxIterations: 20,\n  loopSkip: ['runtime-prep'],\n  engine: 'cursor'\n})\n</code></pre></p>"},{"location":"customizing-workflows/#resolvefolderfoldername-overrides","title":"<code>resolveFolder(folderName, overrides?)</code>","text":"<p>Loads multiple numbered agent files from a folder.</p> <p>Usage: <pre><code>...resolveFolder('codemachine', {\n  engine: 'claude',\n  model: 'opus',\n  modelReasoningEffort: 'medium'\n})\n</code></pre></p> <p>Folder Structure: <pre><code>prompts/templates/codemachine/agents/\n\u251c\u2500\u2500 01-architecture-agent.md\n\u251c\u2500\u2500 02-planning-agent.md\n\u251c\u2500\u2500 03-task-breakdown-agent.md\n\u2514\u2500\u2500 ...\n</code></pre></p> <p>Files are loaded in numerical order (0-, 1-, 2-*, etc.).</p>"},{"location":"customizing-workflows/#complete-override-options-reference","title":"Complete Override Options Reference","text":""},{"location":"customizing-workflows/#step-overrides","title":"Step Overrides","text":"<p>All overrides available for <code>resolveStep()</code> and <code>resolveModule()</code>:</p> Option Type Description Example <code>executeOnce</code> <code>boolean</code> Run step only once per workflow <code>true</code> <code>engine</code> <code>string</code> AI engine to use <code>'claude'</code>, <code>'codex'</code>, <code>'cursor'</code>, <code>'ccr'</code>, <code>'opencode'</code> <code>model</code> <code>string</code> Specific AI model <code>'gpt-5-codex'</code>, <code>'opus'</code>, <code>'gpt-4'</code> <code>modelReasoningEffort</code> <code>string</code> Reasoning depth level <code>'low'</code>, <code>'medium'</code>, <code>'high'</code> <code>agentName</code> <code>string</code> Custom display name <code>'Senior Architect'</code> <code>promptPath</code> <code>string</code> Custom prompt template path <code>'./prompts/custom.md'</code> <code>notCompletedFallback</code> <code>string</code> Fallback agent ID on failure <code>'plan-fallback'</code>"},{"location":"customizing-workflows/#module-specific-overrides","title":"Module-Specific Overrides","text":"<p>Additional options for <code>resolveModule()</code>:</p> Option Type Description Example <code>loopSteps</code> <code>number</code> Steps to go back when looping <code>6</code> <code>loopMaxIterations</code> <code>number</code> Maximum loop iterations <code>20</code> <code>loopSkip</code> <code>string[]</code> Agent IDs to skip in loop <code>['runtime-prep']</code>"},{"location":"customizing-workflows/#engine-model-configuration","title":"Engine &amp; Model Configuration","text":""},{"location":"customizing-workflows/#available-engines","title":"Available Engines","text":"<p>CodeMachine supports the following AI engines:</p> <ol> <li>claude - Anthropic Claude models</li> <li>codex - OpenAI Codex models</li> <li>cursor - Cursor AI models</li> <li>ccr - Claude Code Router CLI (brings your locally configured providers)</li> <li>opencode - OpenCode CLI (provider-agnostic; supply <code>provider/model</code> strings such as <code>anthropic/claude-3.7-sonnet</code>)</li> </ol>"},{"location":"customizing-workflows/#engine-selection-strategy","title":"Engine Selection Strategy","text":"<p>By Task Type: <pre><code>steps: [\n  resolveStep('planning', { engine: 'claude' }),      // Strategic thinking\n  resolveStep('code-gen', { engine: 'codex' }),       // Code generation\n  resolveStep('review', { engine: 'claude' }),        // Analysis &amp; review\n  resolveStep('docs', { engine: 'claude' }),          // Documentation\n  resolveStep('commit', { engine: 'cursor' })         // Git operations\n]\n</code></pre></p> <p>Mixed Engine Workflow: <pre><code>steps: [\n  resolveStep('arch-agent', { engine: 'claude', model: 'opus' }),\n  resolveStep('code-generation', { engine: 'codex', model: 'gpt-5-codex' }),\n  resolveStep('task-sanity-check', { engine: 'codex', model: 'gpt-5' }),\n  resolveStep('git-commit', { engine: 'cursor' })\n]\n</code></pre></p>"},{"location":"customizing-workflows/#model-options","title":"Model Options","text":"<p>Claude Models: - <code>opus</code> - Most capable, best for complex reasoning - <code>sonnet</code> - Balanced performance - <code>haiku</code> - Fast, efficient</p> <p>Codex Models: - <code>gpt-5-codex</code> - Latest code-specialized model - <code>gpt-5</code> - General purpose GPT-5 - <code>gpt-4</code> - Stable, reliable</p> <p>Cursor Models: - Engine-specific models (check Cursor documentation)</p> <p>OpenCode Models: - Provide the CLI-formatted <code>provider/model</code> name directly (e.g., <code>anthropic/claude-3.7-sonnet</code>, <code>openai/gpt-4.1</code>); CodeMachine passes the value through so you can mirror your OpenCode config.</p>"},{"location":"customizing-workflows/#reasoning-effort-levels","title":"Reasoning Effort Levels","text":"<p>Controls how much \"thinking\" the model does:</p> <ul> <li><code>'low'</code> - Fast, direct responses</li> <li><code>'medium'</code> - Balanced thinking and speed (default)</li> <li><code>'high'</code> - Deep reasoning, longer processing</li> </ul> <p>Example: <pre><code>resolveStep('complex-analysis', {\n  engine: 'claude',\n  model: 'sonnet',\n  modelReasoningEffort: 'high'  // Maximum reasoning depth\n})\n</code></pre></p>"},{"location":"customizing-workflows/#engine-selection","title":"Engine Selection","text":"<pre><code>// Planning &amp; Analysis\n{ engine: 'claude', model: 'sonnet' }\n\n// Code Generation\n{ engine: 'codex', model: 'gpt-5-codex' }\n\n// Git Operations\n{ engine: 'cursor' }\n</code></pre>"},{"location":"specification-schema/","title":"Specification schema","text":""},{"location":"specification-schema/#project-specification-schema","title":"Project Specification Schema","text":"<p>This template is designed to scale with your project's needs.</p> <ul> <li>For simple or initial-phase projects, completing Part 1 (The Essentials) is sufficient.</li> <li>For complex, enterprise-grade, or high-fidelity projects, completing Part 2 (Advanced Specifications) is highly recommended to ensure clarity, reduce risk, and guide a more robust architectural design.</li> </ul>"},{"location":"specification-schema/#part-1-the-essentials-core-requirements-for-any-project","title":"Part 1: The Essentials (Core Requirements for Any Project)","text":"<p>This section captures the minimum information required for an AI to understand and build a functional application.</p>"},{"location":"specification-schema/#10-project-overview-required","title":"1.0 Project Overview (Required)","text":"<ul> <li>1.1 Project Name: [e.g., \"SimpleTodo App\"]</li> <li>1.2 Project Goal: A one or two-sentence summary of what the project is meant to achieve.</li> <li>1.3 Target Audience: Who is this for? [e.g., \"General users who need a simple task manager.\"]</li> </ul>"},{"location":"specification-schema/#20-core-functionality-user-journeys-required","title":"2.0 Core Functionality &amp; User Journeys (Required)","text":"<p>Describe the primary features and how users will interact with them. Use RFC keywords (MUST, SHOULD, MAY).</p> <ul> <li>2.1 Core Features List: A high-level, bulleted list of the main capabilities.<ul> <li>Example: User Authentication, Task Management, Profile Settings.</li> </ul> </li> <li>2.2 User Journeys: Step-by-step descriptions of user interactions.<ul> <li>Format: <code>User [action] \u2192 app [keyword] [reaction] \u2192 [outcome]</code></li> <li>Example: User clicks delete \u2192 app MUST show \"are you sure?\" popup \u2192 YES deletes, NO cancels.</li> <li>Example: User submits form \u2192 app MUST check all fields for validation \u2192 show errors OR save and show success.</li> </ul> </li> </ul>"},{"location":"specification-schema/#30-data-models-required","title":"3.0 Data Models (Required)","text":"<p>Define the structure of the data the application will manage.</p> <ul> <li>Format: <code>Entity: field (keyword, [constraints]), ...</code></li> <li>Example (User): <code>email</code> (REQUIRED, valid email), <code>password</code> (REQUIRED, 8+ chars, hashed), <code>name</code> (REQUIRED)</li> <li>Example (Task): <code>title</code> (REQUIRED, 100 chars max), <code>is_complete</code> (REQUIRED, boolean, default=false), <code>due_date</code> (OPTIONAL)</li> </ul>"},{"location":"specification-schema/#40-essential-error-handling-required","title":"4.0 Essential Error Handling (Required)","text":"<p>Describe how the application must behave during common failure scenarios.</p> <ul> <li>No Internet: The app MUST show an \"Offline\" message.</li> <li>Invalid User Input: The app MUST highlight the incorrect field in red with a helpful message.</li> <li>Server Error: The app SHOULD show a generic \"Something went wrong\" message with an option to retry.</li> </ul>"},{"location":"specification-schema/#-","title":"---","text":""},{"location":"specification-schema/#part-2-advanced-specifications-for-complex-or-high-fidelity-projects","title":"Part 2: Advanced Specifications (For Complex or High-Fidelity Projects)","text":"<p>This section adds the formality, detail, and foresight needed for larger, more critical applications.</p>"},{"location":"specification-schema/#50-formal-project-controls-scope-highly-recommended","title":"5.0 Formal Project Controls &amp; Scope (Highly Recommended)","text":"<ul> <li>5.1 Document Control:<ul> <li>Version: [e.g., 1.0] | Status: [e.g., Approved] | Date: [e.g., October 27, 2025]</li> </ul> </li> <li>5.2 Detailed Scope:<ul> <li>In Scope: An explicit bulleted list of functionalities that WILL be delivered.</li> <li>Out of Scope: An explicit bulleted list of functionalities that WILL NOT be delivered to prevent scope creep.</li> </ul> </li> <li>5.3 Glossary of Terms &amp; Acronyms: A table defining all domain-specific terminology (e.g., ESG, CBAM, GHG).</li> </ul>"},{"location":"specification-schema/#60-granular-traceable-requirements-recommended-for-traceability","title":"6.0 Granular &amp; Traceable Requirements (Recommended for Traceability)","text":"<p>This formalizes the User Journeys from Part 1 into a trackable format.</p> ID Requirement Name / User Story Description Priority FR-001 User Login The system MUST allow a registered user to log in with an email and password. Critical FR-002 AI Document Verification The system MUST use an LLM to extract data from uploaded invoices. High"},{"location":"specification-schema/#70-measurable-non-functional-requirements-nfrs-critical-for-architecture","title":"7.0 Measurable Non-Functional Requirements (NFRs) (Critical for Architecture)","text":"<p>Define the quality attributes and constraints. Each NFR should be specific and measurable.</p> ID Category Requirement Metric / Acceptance Criteria NFR-PERF-001 Performance API Response Time 95% of read-only API calls MUST complete in &lt; 250ms. NFR-ACC-001 Accuracy AI Data Extraction Key fields from structured invoices MUST be extracted with &gt;90% accuracy. NFR-REL-001 Reliability System Uptime The service MUST maintain 99.5% uptime. NFR-SEC-001 Security Data Privacy MUST comply with GDPR and KSA PDPL data handling standards. NFR-SCALE-001 Scalability Concurrent Users MUST support 1,000 concurrent users without performance degradation. NFR-EXT-001 Extensibility Future Regulations The architecture MUST allow adding a new reporting framework via configuration, not a code rewrite."},{"location":"specification-schema/#80-technical-architectural-constraints-optional","title":"8.0 Technical &amp; Architectural Constraints (Optional)","text":"<p>Provide specific technical directives if you have them. If not, the AI will propose a suitable architecture.</p> <ul> <li>8.1 Technology Stack: [e.g., Frontend: React, Backend: Node.js, Database: PostgreSQL]</li> <li>8.2 Architectural Principles: [e.g., \"The system MUST be a microservices architecture.\"]</li> <li>8.3 Deployment Environment: [e.g., \"The application MUST be containerized using Docker and deployed to AWS.\"]</li> </ul>"},{"location":"specification-schema/#90-assumptions-dependencies-risks-highly-recommended-for-risk-management","title":"9.0 Assumptions, Dependencies &amp; Risks (Highly Recommended for Risk Management)","text":"<ul> <li>9.1 Assumptions: List statements considered true without proof.<ul> <li>Example: \"Third-party emission factor databases will be accessible via a stable API.\"</li> </ul> </li> <li>9.2 Dependencies: List external factors the project relies on.<ul> <li>Example: \"Project delivery depends on the finalization of EU CBAM implementation rules.\"</li> </ul> </li> </ul>"},{"location":"case-studies/sustaina/","title":"Case Study: Sustaina ESG Compliance Platform","text":""},{"location":"case-studies/sustaina/#ai-orchestrated-development-of-enterprise-grade-sustainability-compliance-system-via-codemachine","title":"AI-Orchestrated Development of Enterprise-Grade Sustainability Compliance System via CodeMachine","text":"<p>Document Version: 1.0 Publication Date: October 13, 2025 Project Duration: 10 weeks Technology Stack: React, Python/FastAPI, Node.js/NestJS, PostgreSQL, MongoDB, Redis, AWS, Kubernetes Generated by: CodeMachine AI Orchestration Platform</p>"},{"location":"case-studies/sustaina/#executive-summary","title":"Executive Summary","text":"<p>Sustaina is an AI-enabled Environmental, Social, and Governance (ESG) compliance platform designed to democratize sustainability reporting for Small and Medium Enterprises (SMEs) in Egypt and the MENA region. The platform transforms complex international regulations\u2014including the EU's Carbon Border Adjustment Mechanism (CBAM), European Sustainability Reporting Standards (ESRS), ISO 14064, and GHG Protocol\u2014into clear, actionable compliance pathways.</p> <p>This case study documents how CodeMachine, a CLI-native AI orchestration platform, transformed a 187-page specification into a production-ready, enterprise-grade system comprising:</p> <ul> <li>7 microservices (Python/FastAPI, Node.js/NestJS)</li> <li>Multi-database architecture (PostgreSQL, MongoDB, Redis, Elasticsearch)</li> <li>Event-driven workflows (Amazon SQS/SNS)</li> <li>Cloud-native infrastructure (AWS EKS, RDS, ElastiCache, S3)</li> <li>Complete CI/CD pipeline (GitHub Actions, ArgoCD, Terraform)</li> <li>Comprehensive monitoring (Prometheus, Grafana, ELK Stack)</li> </ul> <p>Key Achievement: CodeMachine coordinated specialized AI agents across a multi-phase orchestration workflow to deliver 482 production-ready files (60,008 lines of code), complete infrastructure-as-code, and automated deployment pipelines\u2014all generated from specification documents through intelligent agent orchestration.</p>"},{"location":"case-studies/sustaina/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Project Overview</li> <li>Technical Challenge &amp; Requirements</li> <li>CodeMachine Orchestration Platform</li> <li>Architecture &amp; Technology Stack</li> <li>Implementation Strategy</li> <li>Complete Project Structure</li> <li>Key Implementation Patterns</li> <li>Results &amp; Deliverables</li> <li>Technical Metrics</li> </ol>"},{"location":"case-studies/sustaina/#1-project-overview","title":"1. Project Overview","text":""},{"location":"case-studies/sustaina/#11-business-context","title":"1.1 Business Context","text":"<p>SMEs in the MENA region face mounting pressure to demonstrate ESG compliance to access European markets and international financing. The EU's CBAM regulation, effective 2026, requires exporters to report embedded carbon emissions in products. ESRS mandates detailed sustainability disclosures for companies operating in EU markets. For resource-constrained SMEs, navigating these complex, multi-jurisdictional frameworks represents a significant barrier to growth.</p> <p>Sustaina's Mission: Provide an intelligent compliance assistant that: - Automates regulatory intelligence: Maps jurisdiction-specific requirements based on industry, location, and target markets - Simplifies carbon accounting: Calculates product-level Scope 1-3 emissions using verified emission factors - Ensures audit readiness: AI-powered document verification against regulatory requirements - Enables market access: Generates CBAM-compliant reports and ESG disclosures</p>"},{"location":"case-studies/sustaina/#12-project-scope","title":"1.2 Project Scope","text":"<p>Phase 1 (Current): Carbon Accounting &amp; CBAM Compliance - Jurisdiction-aware compliance mapping (EU, UK, KSA, Egypt) - Product-level embedded emissions calculation - AI-powered document processing (invoices, EPDs, energy bills) - Supply chain emission mapping - CBAM report generation - Compliance risk dashboards</p> <p>Phase 2 (Planned): Full ESG Reporting - Materiality-based disclosure filtering (74 ESRS topics \u2192 8-12 material issues) - Social metrics tracking (labor, diversity, human rights) - Governance metrics (ethics, data protection, board composition) - Multi-framework report generation (ESRS, GRI, IFC Performance Standards)</p> <p>Out of Scope: - Carbon credit trading mechanisms - Blockchain-based supply chain traceability (future consideration) - Physical product verification or IoT integration - Direct regulatory submission (system generates compliant reports for manual submission)</p>"},{"location":"case-studies/sustaina/#2-technical-challenge-requirements","title":"2. Technical Challenge &amp; Requirements","text":""},{"location":"case-studies/sustaina/#21-functional-requirements","title":"2.1 Functional Requirements","text":"Requirement ID Description Technical Impact FR-COMP-001 Multi-jurisdiction framework mapping (EU CBAM, ESRS, ISO 14064, KSA PDPL, Egypt regulations) Requires flexible regulatory rule engine with versioned framework definitions in MongoDB FR-CARBON-001 Product-level Scope 1-3 emissions calculation using verified emission factors Demands integration with licensed databases (Ecoinvent, DEFRA, EPA), complex aggregation logic FR-AI-001 Multi-format document ingestion (PDF, images, Excel) with LLM-based field extraction Requires OCR pipeline (PyTesseract) + GPT-4 API integration with prompt engineering FR-CBAM-002 Export-ready CBAM reports (kg CO\u2082e per unit) for EU importers Necessitates PDF generation with standardized templates, S3 storage, audit trails FR-RISK-001 Traffic-light compliance risk scoring (Green/Yellow/Orange/Red) Real-time risk calculation engine with evidence gap detection and remediation logic FR-SC-001 Supply chain emission mapping with substitution logic for missing data Graph-based supplier relationships, intelligent default emission factor selection"},{"location":"case-studies/sustaina/#22-non-functional-requirements","title":"2.2 Non-Functional Requirements","text":"Category Requirement Architectural Solution Performance &lt;60s processing for compliance calculations (\u2264100 suppliers) Asynchronous event-driven workflows (SQS), Redis caching, optimized database queries Accuracy &gt;90% AI extraction accuracy (structured docs), &gt;80% (semi-structured) Multi-stage validation pipeline, confidence scoring, human-in-the-loop for low-confidence extractions Reliability 99.5% uptime (\u22483.6 hours downtime/month) Multi-AZ deployment, health checks, circuit breakers, automated failover (RDS Multi-AZ) Security GDPR and KSA PDPL compliance AES-256 encryption at rest, TLS 1.3 in transit, RBAC, audit logging, regional data residency Scalability 1,000+ concurrent users Horizontal pod auto-scaling (Kubernetes HPA), stateless services, distributed caching Extensibility Easy integration of new ESG frameworks Rule engine with JSON-based framework definitions, versioned APIs, adapter pattern"},{"location":"case-studies/sustaina/#23-technical-constraints","title":"2.3 Technical Constraints","text":"<ol> <li>Multi-Tenancy: Strict data isolation between SME tenants (row-level security with <code>company_id</code> partition key)</li> <li>Regional Compliance: Data residency requirements necessitate multi-region deployment (EU-Central-1 for GDPR, ME-South-1 for KSA PDPL)</li> <li>Document Variability: Must handle diverse document formats with varying quality (handwritten invoices, scanned PDFs, digital exports)</li> <li>Emission Data Licensing: Dependency on third-party databases with annual subscription costs and access limits</li> <li>Regulatory Volatility: CBAM and ESRS specifications evolving, requiring version-controlled framework updates</li> </ol>"},{"location":"case-studies/sustaina/#3-codemachine-orchestration-platform","title":"3. CodeMachine Orchestration Platform","text":""},{"location":"case-studies/sustaina/#31-platform-architecture","title":"3.1 Platform Architecture","text":"<p>CodeMachine is a CLI-native orchestration platform that transforms specification files and contextual inputs into production-ready code through coordinated multi-agent workflows. Unlike traditional code generation tools that produce monolithic outputs, CodeMachine employs:</p> <ol> <li>Hierarchical Agent Orchestration: Specialized AI agents operate in parent-child relationships with bidirectional communication</li> <li>Runtime-Adaptable Methodologies: Dynamic workflow adjustment based on project requirements without framework modifications</li> <li>Context-Aware Task Decomposition: Intelligent breakdown of specifications into parallelizable, dependency-tracked tasks</li> <li>Verification Loops: Continuous validation of generated artifacts against specifications and cross-artifact consistency checks</li> </ol>"},{"location":"case-studies/sustaina/#32-core-components","title":"3.2 Core Components","text":"<pre><code>.codemachine/\n\u251c\u2500\u2500 inputs/\n\u2502   \u2514\u2500\u2500 specifications.md          # Source requirements (187 pages)\n\u251c\u2500\u2500 artifacts/\n\u2502   \u251c\u2500\u2500 architecture/               # Generated architecture blueprints\n\u2502   \u2502   \u251c\u2500\u2500 01_Context_and_Drivers.md\n\u2502   \u2502   \u251c\u2500\u2500 02_Architecture_Overview.md\n\u2502   \u2502   \u251c\u2500\u2500 03_System_Structure_and_Data.md\n\u2502   \u2502   \u251c\u2500\u2500 04_Behavior_and_Communication.md\n\u2502   \u2502   \u251c\u2500\u2500 05_Operational_Architecture.md\n\u2502   \u2502   \u251c\u2500\u2500 06_Rationale_and_Future.md\n\u2502   \u2502   \u2514\u2500\u2500 architecture_manifest.json\n\u2502   \u251c\u2500\u2500 plan/                       # Iteration plans and task breakdowns\n\u2502   \u2502   \u251c\u2500\u2500 01_Plan_Overview_and_Setup.md\n\u2502   \u2502   \u251c\u2500\u2500 02_Iteration_I{1-5}.md\n\u2502   \u2502   \u251c\u2500\u2500 03_Verification_and_Glossary.md\n\u2502   \u2502   \u2514\u2500\u2500 plan_manifest.json\n\u2502   \u2514\u2500\u2500 tasks/                      # Granular task specifications\n\u2502       \u251c\u2500\u2500 tasks_I1.json (11 tasks)\n\u2502       \u251c\u2500\u2500 tasks_I2.json (7 tasks)\n\u2502       \u251c\u2500\u2500 tasks_I3.json (7 tasks)\n\u2502       \u251c\u2500\u2500 tasks_I4.json (7 tasks)\n\u2502       \u251c\u2500\u2500 tasks_I5.json (7 tasks)\n\u2502       \u2514\u2500\u2500 tasks_manifest.json\n\u251c\u2500\u2500 prompts/\n\u2502   \u251c\u2500\u2500 context.md                  # Dynamic context injection\n\u2502   \u251c\u2500\u2500 plan_fallback.md\n\u2502   \u251c\u2500\u2500 task_fallback.md\n\u2502   \u2514\u2500\u2500 code_fallback.md\n\u251c\u2500\u2500 agents/\n\u2502   \u2514\u2500\u2500 agents-config.json          # Agent type registry\n\u2514\u2500\u2500 template.json                   # Workflow orchestration state\n</code></pre>"},{"location":"case-studies/sustaina/#33-orchestration-workflow","title":"3.3 Orchestration Workflow","text":"<p>Phase 1: Specification Analysis <pre><code>Input: specifications.md (187 pages)\n      \u2193\n[Architecture Agent] \u2192 Analyzes requirements, identifies architectural drivers\n      \u2193\nOutput: 6 architecture blueprint documents with C4 diagrams, ERDs, sequence diagrams\n</code></pre></p> <p>Phase 2: Strategic Planning <pre><code>Inputs: Architecture blueprints + specifications\n      \u2193\n[Planning Agent] \u2192 Decomposes into 5 iterations with 39 tasks\n      \u2193\nOutputs:\n  - Iteration plans with goals and acceptance criteria\n  - Task dependency graphs\n  - Parallelization strategy\n  - Verification checkpoints\n</code></pre></p> <p>Phase 3: Task Decomposition <pre><code>Inputs: Iteration plans + architecture context\n      \u2193\n[Task Breakdown Agent] \u2192 Creates granular task specifications\n      \u2193\nOutputs:\n  - tasks_I{1-5}.json (39 total tasks)\n  - Each task includes:\n    * Detailed description\n    * Target files\n    * Input files (dependencies)\n    * Acceptance criteria\n    * Agent type hint (SetupAgent, DatabaseAgent, BackendAgent, etc.)\n    * Parallelization flag\n</code></pre></p> <p>Phase 4: Code Generation &amp; Verification <pre><code>Orchestration Workflow Steps:\n  1. [git-commit] \u2192 Commit initial project specification (Cursor, execute once)\n  2. [arch-agent] \u2192 Define system architecture and technical design (Claude, execute once)\n  3. [plan-agent] \u2192 Generate comprehensive iterative development plan (Claude, execute once)\n  4. [task-breakdown] \u2192 Extract and structure tasks into JSON (Claude, execute once)\n  5. [git-commit] \u2192 Commit task breakdown (Cursor, execute once)\n\n  For each task (loop: max 20 iterations):\n    6. [context-manager] \u2192 Gather relevant context from architecture/plan/codebase (Claude)\n    7. [code-generation] \u2192 Generate code implementation (Codex)\n    8. [cleanup-code-fallback] \u2192 Delete .codemachine/prompts/code_fallback.md if present (Cursor)\n    9. [runtime-prep] \u2192 Generate shell scripts (install, run, lint, test) (Codex, execute once)\n   10. [task-sanity-check] \u2192 Verify code against requirements (Codex)\n   11. [git-commit] \u2192 Commit generated and verified code (Cursor)\n   12. [check-task] \u2192 Loop back if tasks incomplete (Cursor, skip runtime-prep on loops)\n</code></pre></p>"},{"location":"case-studies/sustaina/#34-orchestration-agents","title":"3.4 Orchestration Agents","text":"<p>CodeMachine employs specialized orchestration agents with distinct AI engines:</p> Agent Engine Execution Responsibilities git-commit Cursor Once/Per-task Commits specifications, task breakdowns, and generated code to version control arch-agent Claude Once Analyzes requirements, defines system architecture, creates C4 diagrams, ERDs, and technical design decisions plan-agent Claude Once Generates comprehensive iterative development plan with task decomposition, dependencies, and acceptance criteria task-breakdown Claude Once Extracts and structures tasks from plan into JSON format with detailed specifications, file paths, and agent hints context-manager Claude Per-task Gathers relevant context from architecture blueprints, plan documents, and existing codebase for task execution code-generation Codex Per-task Generates implementation code including microservices, APIs, infrastructure-as-code, frontend components, and tests cleanup-code-fallback Cursor Per-task Removes temporary fallback files from prompts directory to maintain clean workflow state runtime-prep Codex Once Generates robust shell scripts for project automation (install.sh, run.sh, lint.sh, test.sh) task-sanity-check Codex Per-task Verifies generated code against task requirements, acceptance criteria, and architectural constraints check-task Cursor Per-task Evaluates task completion status and triggers loop iteration if tasks remain incomplete (max 20 iterations) <p>Multi-Engine Strategy: - Claude (Sonnet 4.5): Strategic planning, architecture design, context analysis (superior reasoning) - Codex (GPT-5 medium): Code generation, verification, runtime tooling (optimized for code synthesis) - Cursor (Cheetah stealth model): Version control operations, cleanup tasks (file system operations)</p>"},{"location":"case-studies/sustaina/#35-context-injection","title":"3.5 Context Injection","text":"<p>Dynamic Context Provision: Each agent receives task-specific context extracted from: - Architecture blueprints (via <code>architecture_manifest.json</code> anchor references) - Plan documents (via <code>plan_manifest.json</code> section references) - Existing codebase analysis (CodeMachine scans modified files) - Cross-cutting concerns (authentication, logging patterns)</p> <p>Example Context for Task I2.T1 (Document Processing Service): <pre><code>### Context: component-diagram (from docs/architecture/03_System_Structure_and_Data.md)\nShows Document Processing Service internal components:\n- Upload API Controller\n- OCR Engine (PyTesseract)\n- LLM Extraction Pipeline (LangChain + GPT-4)\n- Validation Engine (Regulatory ruleset checker)\n- Evidence Repository (S3 integration)\n- Event Publisher (SQS)\n\n### Relevant Existing Code\n- File: scripts/schema.sql:45\n  Summary: Document table with columns: document_id, company_id, document_type,\n           s3_key, file_size, uploaded_at, status\n  Recommendation: Use this schema for database models; add foreign key to DocumentExtraction\n</code></pre></p>"},{"location":"case-studies/sustaina/#4-architecture-technology-stack","title":"4. Architecture &amp; Technology Stack","text":""},{"location":"case-studies/sustaina/#41-architectural-style","title":"4.1 Architectural Style","text":"<p>Event-Driven Microservices Architecture</p> <p>Rationale: 1. Domain Separation: 7 microservices aligned with business capabilities (Compliance, Carbon Accounting, Document Processing, Risk Assessment, Supply Chain, ESG Reporting, Notifications) 2. Asynchronous Processing: Document analysis and emissions calculations are time-intensive (violates 60s SLA if synchronous) 3. Independent Scaling: AI processing requires more compute than compliance mapping 4. Technology Diversity: Python for AI/ML workloads, Node.js for high-throughput CRUD APIs 5. Resilience: Service isolation prevents cascading failures (critical for 99.5% uptime target)</p> <p>Event Flows: - Document Processing: Upload \u2192 OCR \u2192 LLM Extraction \u2192 Validation \u2192 Risk Update \u2192 Notification - Carbon Calculation: Request \u2192 Supplier Fetch \u2192 Emission Factor Lookup \u2192 Calculation \u2192 Report Generation \u2192 Notification</p>"},{"location":"case-studies/sustaina/#42-technology-stack","title":"4.2 Technology Stack","text":""},{"location":"case-studies/sustaina/#frontend-layer","title":"Frontend Layer","text":"<ul> <li>Framework: React 18 with TypeScript</li> <li>State Management: React Query (server state), Context API (UI state)</li> <li>Styling: Tailwind CSS with custom design system</li> <li>Build Tools: Vite (fast HMR, optimized production builds)</li> <li>Internationalization: i18next (English, Arabic)</li> </ul>"},{"location":"case-studies/sustaina/#api-layer","title":"API Layer","text":"<ul> <li>Gateway: Kong Gateway (JWT validation, rate limiting, routing)</li> <li>Protocol: RESTful APIs with OpenAPI 3.1 specifications</li> <li>Documentation: Auto-generated Swagger UI and Redoc</li> </ul>"},{"location":"case-studies/sustaina/#backend-services","title":"Backend Services","text":"<p>AI/ML Services (Python 3.11 + FastAPI): - Document Processing Service - Carbon Accounting Service - Compliance Engine Service - ESG Reporting Service</p> <p>CRUD APIs (Node.js 20 + NestJS): - Risk Assessment Service - Supply Chain Service - Notification Service</p> <p>Key Libraries: - AI: LangChain, OpenAI SDK, PyTesseract, PyPDF2, Pillow - Calculations: NumPy, Pandas (emissions aggregation) - Validation: Pydantic (FastAPI), class-validator (NestJS)</p>"},{"location":"case-studies/sustaina/#data-layer","title":"Data Layer","text":"<ul> <li>Primary Database: PostgreSQL 15 (AWS RDS Multi-AZ)</li> <li>ACID compliance for financial/regulatory data</li> <li>JSON columns for flexible framework definitions</li> <li>PostGIS for geospatial jurisdiction mapping</li> <li>Document Store: MongoDB Atlas (AWS DocumentDB)</li> <li>Regulatory framework schemas (CBAM, ESRS, ISO)</li> <li>Flexible schema for evolving regulations</li> <li>Cache: Redis 7 (AWS ElastiCache)</li> <li>Emission factor caching (30-day TTL)</li> <li>API response caching (5-minute TTL for dashboards)</li> <li>Session management</li> <li>Object Storage: AWS S3</li> <li>Document storage (invoices, EPDs, certificates)</li> <li>Generated reports (CBAM PDFs, audit packs)</li> <li>AES-256 encryption, versioning for audit trails</li> <li>Search Engine: Elasticsearch 8 (AWS OpenSearch)</li> <li>Full-text search for regulations</li> <li>Supplier lookup</li> <li>Audit log analysis</li> </ul>"},{"location":"case-studies/sustaina/#message-event-layer","title":"Message &amp; Event Layer","text":"<ul> <li>Message Queue: Amazon SQS (Standard + FIFO queues)</li> <li>Event Bus: Amazon SNS (Pub/Sub patterns)</li> <li>Dead Letter Queue: SQS DLQ for failed message handling</li> </ul>"},{"location":"case-studies/sustaina/#infrastructure-deployment","title":"Infrastructure &amp; Deployment","text":"<ul> <li>Containerization: Docker (all microservices)</li> <li>Orchestration: Amazon EKS (Kubernetes 1.28+)</li> <li>IaC: Terraform (VPC, EKS, RDS, ElastiCache, S3, SQS modules)</li> <li>Service Mesh: Istio (mTLS, circuit breakers, distributed tracing)</li> <li>CI/CD: GitHub Actions (pipelines), ArgoCD (GitOps deployments)</li> </ul>"},{"location":"case-studies/sustaina/#monitoring-observability","title":"Monitoring &amp; Observability","text":"<ul> <li>Metrics: Prometheus + Grafana dashboards</li> <li>Logging: ELK Stack (Elasticsearch, Logstash, Kibana) + CloudWatch</li> <li>Tracing: Jaeger (distributed tracing across microservices)</li> <li>Alerting: PagerDuty (critical), Slack (warnings)</li> </ul>"},{"location":"case-studies/sustaina/#security-authentication","title":"Security &amp; Authentication","text":"<ul> <li>Identity Provider: Auth0 (OAuth2/OIDC, enterprise SSO)</li> <li>Secrets Management: HashiCorp Vault</li> <li>Security Scanning: OWASP ZAP (DAST), Snyk (dependencies), SonarQube (SAST)</li> </ul>"},{"location":"case-studies/sustaina/#43-data-model-overview","title":"4.3 Data Model Overview","text":"<p>Core Entities (15 tables in PostgreSQL):</p> <p>Multi-Tenancy: - <code>Company</code>: Tenant entity (partition key <code>company_id</code>, jurisdiction, industry, target markets) - <code>User</code>: Role-based access (admin, compliance_officer, auditor, supply_chain_manager)</p> <p>Compliance Management: - <code>ComplianceChecklist</code>: Generated checklist per company (jurisdiction, frameworks, risk score) - <code>ChecklistItem</code>: Individual requirements (status, evidence links, due dates) - <code>ComplianceReport</code>: Generated reports (CBAM, ESRS, GRI) with S3 keys</p> <p>Carbon Accounting: - <code>Product</code>: SME products (HS codes, bill of materials, unit of measure) - <code>Supplier</code>: Supply chain entities (tier levels, location, sector) - <code>ProductSupplier</code>: Many-to-many with quantities - <code>EmissionCalculation</code>: Product-level footprint (Scope 1-3 breakdown, total CO\u2082e, quality score) - <code>EmissionFactor</code>: Cached factors (region, sector, activity, CO\u2082e per unit, source, validity)</p> <p>Document Management: - <code>Document</code>: Uploaded evidence (S3 keys, document type, metadata) - <code>DocumentExtraction</code>: AI-extracted fields (JSON), confidence scores, validation status</p> <p>Audit &amp; Risk: - <code>AuditLog</code>: Immutable append-only log (user actions, timestamps, IP addresses) - <code>RiskAssessment</code>: Historical risk scores with traffic-light indicators</p> <p>MongoDB Collections: - <code>RegulatoryFramework</code>: JSON documents (CBAM, ESRS, ISO 14064, GRI)   - Disclosure requirements   - Calculation methods   - Evidence types   - Thresholds   - Temporal versioning (CBAM v1.0 \u2192 v1.1)</p>"},{"location":"case-studies/sustaina/#44-api-design-principles","title":"4.4 API Design Principles","text":"<p>RESTful Conventions: - Resource-Oriented URLs: <code>/companies/{companyId}/products</code>, <code>/documents/{documentId}/extractions</code> - HTTP Verbs: GET (retrieval), POST (creation), PUT (update), DELETE (removal) - Status Codes: 200 OK, 201 Created, 202 Accepted, 400 Bad Request, 401 Unauthorized, 404 Not Found, 500 Internal Server Error - Error Format: RFC 7807 Problem Details (<code>type</code>, <code>title</code>, <code>status</code>, <code>detail</code>)</p> <p>Asynchronous Operations: - Long-running tasks return <code>202 Accepted</code> with <code>Location</code> header - Clients poll status endpoint: <code>/api/v1/carbon/calculations/{id}</code> \u2192 <code>{status: \"completed\", result: {...}}</code></p> <p>Key Endpoints: - <code>POST /api/v1/compliance/checklists</code> - Generate jurisdiction-specific checklist - <code>POST /api/v1/carbon/calculations</code> - Calculate product emissions (async) - <code>POST /api/v1/documents</code> - Upload document (returns presigned S3 URL) - <code>POST /api/v1/documents/{id}/extract</code> - Trigger AI extraction (async) - <code>GET /api/v1/risk/scores/{companyId}</code> - Compliance risk score</p>"},{"location":"case-studies/sustaina/#5-implementation-strategy","title":"5. Implementation Strategy","text":""},{"location":"case-studies/sustaina/#51-iteration-based-delivery","title":"5.1 Iteration-Based Delivery","text":"<p>Iteration 1 (Foundation): Project Setup &amp; Core Artifacts (2 weeks) - Goal: Establish infrastructure, data models, diagrams, API specs - Tasks: 11 tasks (Setup, Diagrams, Database, Terraform, OpenAPI, Seed Scripts, Shared Libraries) - Deliverables:   - Complete monorepo structure   - PostgreSQL schema (15 tables) + MongoDB schemas   - PlantUML diagrams (Context, Container, Component, ERD, Deployment)   - OpenAPI 3.1 specs (5 services + consolidated)   - Terraform modules (VPC, EKS, RDS, ElastiCache)   - TypeScript API client (auto-generated)   - Seed scripts (emission factors, regulatory frameworks)   - Shared Python/Node.js libraries</p> <p>Iteration 2 (Core Services): Document Processing &amp; Carbon Accounting (2 weeks) - Goal: Implement primary business logic for Phase 1 - Tasks: 7 tasks (Document Service APIs, OCR+LLM pipeline, Validation, Carbon calculation engine, Sequence diagrams, Postman collection, Tests) - Deliverables:   - Document Processing Service (S3 presigned URLs, PyTesseract OCR, GPT-4 extraction, validation engine)   - Carbon Accounting Service (GHG Protocol calculation, CBAM report generation)   - Sequence diagrams (Document workflow, CBAM calculation)   - Postman collection (20+ API requests)   - Unit + integration tests (&gt;80% coverage)</p> <p>Iteration 3 (Compliance &amp; UI): Compliance Engine, Risk, Supply Chain, Dashboard (2 weeks) - Goal: Complete Phase 1 feature set with frontend - Tasks: 7 tasks (Compliance Engine, Risk Service, Supply Chain Service, Notification Service, React Dashboard, E2E tests, Staging deployment) - Deliverables:   - Compliance Engine (framework mapping, checklist generation)   - Risk Assessment Service (traffic-light scoring, gap analysis)   - Supply Chain Service (supplier mapping, emission factor substitution)   - Notification Service (email alerts, WebSocket notifications)   - Compliance Dashboard (React, risk visualization, document uploads)   - End-to-end integration tests   - Deployed to AWS staging (ArgoCD)</p> <p>Iteration 4 (Production Readiness): Integration, Security, Performance (2 weeks) - Goal: Harden system for production deployment - Tasks: 7 tasks (Kong Gateway, CloudFront deployment, Playwright E2E, Load testing, Security scanning, Production infrastructure, UAT) - Deliverables:   - Kong Gateway with JWT auth and rate limiting   - Web app on S3 + CloudFront CDN   - Playwright E2E tests (compliance, carbon, CBAM workflows)   - Load testing reports (k6: 1000 concurrent users)   - OWASP ZAP security scan results   - Blue-green deployment infrastructure   - UAT with 5 pilot SME customers</p> <p>Iteration 5 (ESG Expansion - Planned): Full ESG Reporting (3 weeks) - Goal: Phase 2 features - ESRS, GRI, social/governance metrics - Tasks: 7 tasks (Data model extension, ESG Reporting Service, Social metrics, Governance metrics, ESRS/GRI report generation, ESG Dashboard, Deployment)</p>"},{"location":"case-studies/sustaina/#52-verification-strategy","title":"5.2 Verification Strategy","text":"<p>Artifact Validation: - PlantUML Diagrams: Must render without syntax errors using PlantUML CLI - OpenAPI Specs: Validated with <code>openapi-generator-cli</code> and Swagger Editor - SQL DDL: Executed on PostgreSQL 15 without errors - Terraform: <code>terraform validate</code> passes, <code>terraform plan</code> generates valid execution plan - TypeScript Client: Compiles with <code>tsc</code> without errors - Tests: &gt;80% code coverage requirement</p> <p>Cross-Artifact Consistency Checks: - ERD entities match SQL schema tables - OpenAPI schemas align with database models - Sequence diagrams validated against implemented API flows - Environment variables in Terraform outputs match service configurations</p>"},{"location":"case-studies/sustaina/#6-complete-project-structure","title":"6. Complete Project Structure","text":"<pre><code>sustaina-platform/\n\u251c\u2500\u2500 .github/                                    # CI/CD Workflows\n\u2502   \u2514\u2500\u2500 workflows/\n\u2502       \u251c\u2500\u2500 ci-backend.yml                     # Backend tests, linting, Docker builds\n\u2502       \u251c\u2500\u2500 ci-frontend.yml                    # Frontend tests, build\n\u2502       \u251c\u2500\u2500 cd-staging.yml                     # Deploy to staging\n\u2502       \u251c\u2500\u2500 cd-production.yml                  # Deploy to production (manual)\n\u2502       \u2514\u2500\u2500 cd-web-app.yml                     # Web app S3 + CloudFront deployment\n\u2502\n\u251c\u2500\u2500 services/                                   # Microservices (7 services)\n\u2502   \u251c\u2500\u2500 compliance-service/                    # Python/FastAPI\n\u2502   \u2502   \u251c\u2500\u2500 src/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 api/                          # Route handlers\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 checklists.py             # POST/GET /checklists\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 frameworks.py             # GET /frameworks\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 health.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 core/                         # Business logic\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 checklist_generator.py    # Jurisdiction-aware checklist logic\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 framework_loader.py       # MongoDB framework queries\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 rule_engine.py            # Regulatory rule evaluation\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 models/                       # SQLAlchemy ORM\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 company.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 checklist.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 checklist_item.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 schemas/                      # Pydantic validation\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 checklist_request.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 checklist_response.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 main.py                       # FastAPI app entry point\n\u2502   \u2502   \u251c\u2500\u2500 tests/                            # Pytest\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 test_checklist_generator.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 test_frameworks.py\n\u2502   \u2502   \u251c\u2500\u2500 Dockerfile                        # Multi-stage build\n\u2502   \u2502   \u251c\u2500\u2500 requirements.txt\n\u2502   \u2502   \u2514\u2500\u2500 README.md\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 carbon-accounting-service/            # Python/FastAPI\n\u2502   \u2502   \u251c\u2500\u2500 src/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 api/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 calculations.py           # POST /calculations, GET /calculations/{id}\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 reports.py                # POST /reports/cbam\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 emission_factors.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 core/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 ghg_calculator.py         # Scope 1-3 calculation engine\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 cbam_generator.py         # CBAM PDF report generation\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 emission_factor_service.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 models/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 product.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 emission_calculation.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 emission_factor.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 schemas/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 workers/                      # Async workers\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 calculation_worker.py     # SQS consumer\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 main.py\n\u2502   \u2502   \u251c\u2500\u2500 tests/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 test_ghg_calculator.py        # Verify calculation accuracy (&lt;5% variance)\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 test_cbam_generator.py\n\u2502   \u2502   \u251c\u2500\u2500 Dockerfile\n\u2502   \u2502   \u251c\u2500\u2500 requirements.txt\n\u2502   \u2502   \u2514\u2500\u2500 README.md\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 document-processing-service/          # Python/FastAPI\n\u2502   \u2502   \u251c\u2500\u2500 src/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 api/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 documents.py              # POST /documents, POST /documents/{id}/extract\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 validations.py            # GET /documents/{id}/validation\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 core/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 ocr.py                    # PyTesseract + PyPDF2 integration\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 llm_pipeline.py           # LangChain + GPT-4 extraction\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 validator.py              # Regulatory ruleset validation\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 s3_client.py              # S3 presigned URL generation\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 models/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 document.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 document_extraction.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 schemas/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 workers/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 ocr_worker.py             # SQS consumer for OCR\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 extraction_worker.py      # SQS consumer for LLM\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 validation_worker.py\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 main.py\n\u2502   \u2502   \u251c\u2500\u2500 tests/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 test_ocr.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 test_llm_pipeline.py          # Mock GPT-4 calls\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 test_validator.py\n\u2502   \u2502   \u251c\u2500\u2500 Dockerfile\n\u2502   \u2502   \u251c\u2500\u2500 requirements.txt\n\u2502   \u2502   \u2514\u2500\u2500 README.md\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 risk-assessment-service/              # Node.js/NestJS\n\u2502   \u2502   \u251c\u2500\u2500 src/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 controllers/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 risk.controller.ts        # GET /scores/{companyId}, GET /gaps\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 health.controller.ts\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 services/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 risk-calculator.service.ts # Traffic-light scoring algorithm\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 gap-analyzer.service.ts    # Evidence gap detection\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 recommendation.service.ts\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 entities/\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 risk-assessment.entity.ts  # TypeORM entity\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 dto/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 risk-score.dto.ts\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 gap-analysis.dto.ts\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 consumers/\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 document-validated.consumer.ts # SQS consumer\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 main.ts                        # NestJS bootstrap\n\u2502   \u2502   \u251c\u2500\u2500 test/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 risk-calculator.service.spec.ts\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 gap-analyzer.service.spec.ts\n\u2502   \u2502   \u251c\u2500\u2500 Dockerfile\n\u2502   \u2502   \u251c\u2500\u2500 package.json\n\u2502   \u2502   \u251c\u2500\u2500 tsconfig.json\n\u2502   \u2502   \u2514\u2500\u2500 README.md\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 supply-chain-service/                  # Node.js/NestJS\n\u2502   \u2502   \u251c\u2500\u2500 src/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 controllers/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 suppliers.controller.ts    # CRUD /suppliers\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 product-suppliers.controller.ts\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 services/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 supplier.service.ts\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 product-supplier.service.ts\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 emission-factor.service.ts # Default factor substitution\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 entities/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 supplier.entity.ts\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 product-supplier.entity.ts\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 dto/\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 main.ts\n\u2502   \u2502   \u251c\u2500\u2500 test/\n\u2502   \u2502   \u251c\u2500\u2500 Dockerfile\n\u2502   \u2502   \u251c\u2500\u2500 package.json\n\u2502   \u2502   \u2514\u2500\u2500 README.md\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 esg-reporting-service/                 # Python/FastAPI (Phase 2)\n\u2502   \u2502   \u251c\u2500\u2500 src/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 api/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 materiality.py\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 esg_metrics.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 reports.py                 # POST /reports/esrs, POST /reports/gri\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 core/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 materiality_assessor.py   # Filter 74 ESRS topics \u2192 8-12 material\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 esg_calculator.py\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 report_generator.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 models/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 schemas/\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 main.py\n\u2502   \u2502   \u251c\u2500\u2500 tests/\n\u2502   \u2502   \u251c\u2500\u2500 Dockerfile\n\u2502   \u2502   \u251c\u2500\u2500 requirements.txt\n\u2502   \u2502   \u2514\u2500\u2500 README.md\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 notification-service/                  # Node.js/NestJS\n\u2502       \u251c\u2500\u2500 src/\n\u2502       \u2502   \u251c\u2500\u2500 controllers/\n\u2502       \u2502   \u2502   \u2514\u2500\u2500 notifications.controller.ts\n\u2502       \u2502   \u251c\u2500\u2500 services/\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 email.service.ts           # SendGrid/SES integration\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 websocket.service.ts       # Socket.io for real-time notifications\n\u2502       \u2502   \u2502   \u2514\u2500\u2500 template.service.ts\n\u2502       \u2502   \u251c\u2500\u2500 consumers/\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 compliance-risk-changed.consumer.ts\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 calculation-completed.consumer.ts\n\u2502       \u2502   \u2502   \u2514\u2500\u2500 document-validated.consumer.ts\n\u2502       \u2502   \u251c\u2500\u2500 templates/                     # Email templates (Handlebars)\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 compliance-alert.hbs\n\u2502       \u2502   \u2502   \u2514\u2500\u2500 calculation-complete.hbs\n\u2502       \u2502   \u2514\u2500\u2500 main.ts\n\u2502       \u251c\u2500\u2500 test/\n\u2502       \u251c\u2500\u2500 Dockerfile\n\u2502       \u251c\u2500\u2500 package.json\n\u2502       \u2514\u2500\u2500 README.md\n\u2502\n\u251c\u2500\u2500 web-app/                                    # React Frontend (SPA)\n\u2502   \u251c\u2500\u2500 public/\n\u2502   \u2502   \u251c\u2500\u2500 favicon.ico\n\u2502   \u2502   \u2514\u2500\u2500 index.html\n\u2502   \u251c\u2500\u2500 src/\n\u2502   \u2502   \u251c\u2500\u2500 components/                        # Reusable UI components\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 Button.tsx\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 Card.tsx\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 Modal.tsx\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 Table.tsx\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 Spinner.tsx\n\u2502   \u2502   \u251c\u2500\u2500 features/                          # Feature modules\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 compliance/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 ComplianceDashboard.tsx\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 ChecklistView.tsx\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 FrameworkSelector.tsx\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 carbon/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 ProductList.tsx\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 CalculationForm.tsx\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 CBAMReportView.tsx\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 documents/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 DocumentUpload.tsx\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 DocumentList.tsx\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 ValidationStatus.tsx\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 risk/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 RiskDashboard.tsx\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 TrafficLightIndicator.tsx\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 GapAnalysis.tsx\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 auth/\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 LoginPage.tsx\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 Profile.tsx\n\u2502   \u2502   \u251c\u2500\u2500 api/                               # API client\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 client.ts                     # Axios config + generated client wrapper\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 hooks/                        # React Query hooks\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 useChecklists.ts\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 useCalculations.ts\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 useDocuments.ts\n\u2502   \u2502   \u251c\u2500\u2500 utils/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 formatters.ts                 # Date, number, currency formatting\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 validators.ts\n\u2502   \u2502   \u251c\u2500\u2500 hooks/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 useAuth.ts\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 useToast.ts\n\u2502   \u2502   \u251c\u2500\u2500 i18n/                             # Internationalization\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 en.json                       # English translations\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 ar.json                       # Arabic translations\n\u2502   \u2502   \u251c\u2500\u2500 App.tsx\n\u2502   \u2502   \u251c\u2500\u2500 main.tsx\n\u2502   \u2502   \u2514\u2500\u2500 vite-env.d.ts\n\u2502   \u251c\u2500\u2500 tests/                                # Jest + React Testing Library\n\u2502   \u2502   \u251c\u2500\u2500 ComplianceDashboard.test.tsx\n\u2502   \u2502   \u2514\u2500\u2500 DocumentUpload.test.tsx\n\u2502   \u251c\u2500\u2500 .env.staging                          # Environment variables\n\u2502   \u251c\u2500\u2500 .env.production\n\u2502   \u251c\u2500\u2500 package.json\n\u2502   \u251c\u2500\u2500 vite.config.ts\n\u2502   \u251c\u2500\u2500 tailwind.config.js\n\u2502   \u251c\u2500\u2500 tsconfig.json\n\u2502   \u2514\u2500\u2500 README.md\n\u2502\n\u251c\u2500\u2500 infrastructure/                            # Infrastructure as Code\n\u2502   \u251c\u2500\u2500 terraform/\n\u2502   \u2502   \u251c\u2500\u2500 environments/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 dev/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 main.tf                  # Wires modules for dev environment\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 terraform.tfvars         # Dev-specific variables\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 backend.tf               # S3 backend for state\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 staging/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 main.tf\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 web-app.tf               # S3 + CloudFront for web app\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 terraform.tfvars\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 production/\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 main.tf\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 terraform.tfvars\n\u2502   \u2502   \u251c\u2500\u2500 modules/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 vpc/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 main.tf                  # VPC, subnets, NAT, IGW, route tables\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 variables.tf\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 outputs.tf\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 eks/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 main.tf                  # EKS cluster, node groups, RBAC\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 variables.tf\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 outputs.tf\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 rds/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 main.tf                  # PostgreSQL Multi-AZ, backups, encryption\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 variables.tf\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 outputs.tf\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 elasticache/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 main.tf                  # Redis cluster, cross-AZ replication\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 variables.tf\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 outputs.tf\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 s3/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 main.tf                  # S3 buckets (documents, backups, logs)\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 variables.tf\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 outputs.tf\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 s3-web-hosting/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 main.tf                  # S3 static site + CloudFront + ACM + Route53\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 variables.tf\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 outputs.tf\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 sqs/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 main.tf                  # SQS queues, SNS topics, DLQs\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 variables.tf\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 outputs.tf\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 monitoring/\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 main.tf                  # CloudWatch dashboards, alarms\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 variables.tf\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 outputs.tf\n\u2502   \u2502   \u2514\u2500\u2500 README.md\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 kubernetes/                           # Kubernetes manifests\n\u2502   \u2502   \u251c\u2500\u2500 base/                            # Base configs\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 namespaces.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 rbac.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 kong-plugins.yaml            # JWT auth, rate limiting plugins\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 kong-routes.yaml\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 kong-health.yaml\n\u2502   \u2502   \u251c\u2500\u2500 helm-charts/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 compliance-service/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 templates/\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 deployment.yaml\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 service.yaml\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 ingress.yaml\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 hpa.yaml             # Horizontal Pod Autoscaler\n\u2502   \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 servicemonitor.yaml  # Prometheus scraping\n\u2502   \u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 external-secret.yaml # External Secrets Operator\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 values.yaml\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 values-staging.yaml\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 Chart.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 carbon-accounting-service/\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 ... (same structure)\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 document-processing-service/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 risk-assessment-service/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 supply-chain-service/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 notification-service/\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 kong-gateway/\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 ... (same structure)\n\u2502   \u2502   \u2514\u2500\u2500 argocd/                          # GitOps application definitions\n\u2502   \u2502       \u251c\u2500\u2500 staging/\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 compliance-app.yaml\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 carbon-app.yaml\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 document-app.yaml\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 risk-app.yaml\n\u2502   \u2502       \u2502   \u251c\u2500\u2500 supply-chain-app.yaml\n\u2502   \u2502       \u2502   \u2514\u2500\u2500 kong-app.yaml\n\u2502   \u2502       \u2514\u2500\u2500 production/\n\u2502   \u2502           \u2514\u2500\u2500 ... (same structure)\n\u2502\n\u251c\u2500\u2500 docs/                                     # Documentation\n\u2502   \u251c\u2500\u2500 architecture/                        # Architecture blueprints\n\u2502   \u2502   \u251c\u2500\u2500 01_Context_and_Drivers.md\n\u2502   \u2502   \u251c\u2500\u2500 02_Architecture_Overview.md\n\u2502   \u2502   \u251c\u2500\u2500 03_System_Structure_and_Data.md\n\u2502   \u2502   \u251c\u2500\u2500 04_Behavior_and_Communication.md\n\u2502   \u2502   \u251c\u2500\u2500 05_Operational_Architecture.md\n\u2502   \u2502   \u251c\u2500\u2500 06_Rationale_and_Future.md\n\u2502   \u2502   \u251c\u2500\u2500 architecture_manifest.json\n\u2502   \u2502   \u2514\u2500\u2500 README.md\n\u2502   \u251c\u2500\u2500 diagrams/                            # PlantUML diagrams\n\u2502   \u2502   \u251c\u2500\u2500 c4-context.puml                 # System context (external actors)\n\u2502   \u2502   \u251c\u2500\u2500 c4-container.puml               # Container diagram (microservices, DBs)\n\u2502   \u2502   \u251c\u2500\u2500 c4-component-docprocessing.puml # Document Service internals\n\u2502   \u2502   \u251c\u2500\u2500 erd-data-model.puml             # Entity-Relationship Diagram\n\u2502   \u2502   \u251c\u2500\u2500 seq-document-upload.puml        # Sequence: Document workflow\n\u2502   \u2502   \u251c\u2500\u2500 seq-cbam-calculation.puml       # Sequence: CBAM calculation\n\u2502   \u2502   \u2514\u2500\u2500 deployment-aws.puml             # AWS infrastructure deployment\n\u2502   \u251c\u2500\u2500 adr/                                 # Architectural Decision Records\n\u2502   \u2502   \u251c\u2500\u2500 001-event-driven-architecture.md\n\u2502   \u2502   \u251c\u2500\u2500 002-polyglot-persistence.md\n\u2502   \u2502   \u251c\u2500\u2500 003-external-llm-apis.md\n\u2502   \u2502   \u2514\u2500\u2500 README.md\n\u2502   \u251c\u2500\u2500 api-specs/\n\u2502   \u2502   \u2514\u2500\u2500 api-overview.md                 # API documentation overview\n\u2502   \u2514\u2500\u2500 runbooks/\n\u2502       \u251c\u2500\u2500 deploy-staging.md               # Staging deployment procedure\n\u2502       \u251c\u2500\u2500 disaster-recovery.md            # DR procedures (RTO 4h, RPO 1h)\n\u2502       \u2514\u2500\u2500 incident-response.md            # Incident handling playbook\n\u2502\n\u251c\u2500\u2500 api/                                      # OpenAPI Specifications\n\u2502   \u251c\u2500\u2500 openapi-v1.yaml                      # Consolidated spec (all services)\n\u2502   \u251c\u2500\u2500 compliance-service.yaml\n\u2502   \u251c\u2500\u2500 carbon-accounting-service.yaml\n\u2502   \u251c\u2500\u2500 document-processing-service.yaml\n\u2502   \u251c\u2500\u2500 risk-assessment-service.yaml\n\u2502   \u2514\u2500\u2500 supply-chain-service.yaml\n\u2502\n\u251c\u2500\u2500 shared/                                   # Shared libraries\n\u2502   \u251c\u2500\u2500 typescript-client/                   # Auto-generated API client\n\u2502   \u2502   \u251c\u2500\u2500 src/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 apis/                       # ComplianceApi, CarbonAccountingApi, etc.\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 models/                     # Type definitions (ComplianceChecklist, Product, etc.)\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 index.ts\n\u2502   \u2502   \u251c\u2500\u2500 package.json\n\u2502   \u2502   \u251c\u2500\u2500 tsconfig.json\n\u2502   \u2502   \u2514\u2500\u2500 README.md\n\u2502   \u251c\u2500\u2500 python-common/                       # Shared Python utilities\n\u2502   \u2502   \u251c\u2500\u2500 sustaina_common/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 database.py                 # SQLAlchemy session factory\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 logging.py                  # Structured JSON logging\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 config.py                   # Environment variable loader\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 models.py                   # BaseModel (id, company_id, timestamps)\n\u2502   \u2502   \u251c\u2500\u2500 tests/\n\u2502   \u2502   \u251c\u2500\u2500 setup.py\n\u2502   \u2502   \u251c\u2500\u2500 requirements.txt\n\u2502   \u2502   \u2514\u2500\u2500 README.md\n\u2502   \u2514\u2500\u2500 node-common/                         # Shared Node.js utilities\n\u2502       \u251c\u2500\u2500 src/\n\u2502       \u2502   \u251c\u2500\u2500 database.ts                 # TypeORM DataSource factory\n\u2502       \u2502   \u251c\u2500\u2500 logging.ts                  # Winston JSON logger\n\u2502       \u2502   \u251c\u2500\u2500 config.ts                   # dotenv loader\n\u2502       \u2502   \u2514\u2500\u2500 middleware.ts               # JWT validation, error handling\n\u2502       \u251c\u2500\u2500 tests/\n\u2502       \u251c\u2500\u2500 package.json\n\u2502       \u251c\u2500\u2500 tsconfig.json\n\u2502       \u2514\u2500\u2500 README.md\n\u2502\n\u251c\u2500\u2500 scripts/                                  # Utility scripts\n\u2502   \u251c\u2500\u2500 schema.sql                           # PostgreSQL DDL (15 tables, indexes)\n\u2502   \u251c\u2500\u2500 emission-factors-schema.sql\n\u2502   \u251c\u2500\u2500 mongodb-schemas.json                 # RegulatoryFramework JSON Schema\n\u2502   \u251c\u2500\u2500 seed-emission-factors.py             # Load 30+ emission factors (DEFRA, EPA)\n\u2502   \u251c\u2500\u2500 seed-regulatory-frameworks.py        # Load CBAM, ISO 14064, GHG Protocol\n\u2502   \u251c\u2500\u2500 generate-test-data.py               # Generate sample SME data\n\u2502   \u251c\u2500\u2500 deploy-web-app.sh                   # Web app deployment script\n\u2502   \u251c\u2500\u2500 backup-databases.sh\n\u2502   \u251c\u2500\u2500 emission-data/\n\u2502   \u2502   \u2514\u2500\u2500 defra-2024-factors.csv\n\u2502   \u251c\u2500\u2500 frameworks-data/\n\u2502   \u2502   \u251c\u2500\u2500 cbam-eu-2026.json\n\u2502   \u2502   \u251c\u2500\u2500 iso-14064.json\n\u2502   \u2502   \u2514\u2500\u2500 ghg-protocol.json\n\u2502   \u2514\u2500\u2500 migrations/\n\u2502       \u2514\u2500\u2500 001_initial_schema.sql\n\u2502\n\u251c\u2500\u2500 tests/                                    # End-to-end &amp; integration tests\n\u2502   \u251c\u2500\u2500 e2e/                                 # Playwright tests\n\u2502   \u2502   \u251c\u2500\u2500 compliance-workflow.spec.ts     # Generate checklist \u2192 upload docs \u2192 view risk\n\u2502   \u2502   \u251c\u2500\u2500 carbon-calculation.spec.ts      # Create product \u2192 add suppliers \u2192 calculate\n\u2502   \u2502   \u2514\u2500\u2500 cbam-report.spec.ts             # Generate CBAM report \u2192 download PDF\n\u2502   \u251c\u2500\u2500 integration/                         # Cross-service tests\n\u2502   \u2502   \u251c\u2500\u2500 fixtures/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 sample-invoice.pdf\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 sample-epd.xlsx\n\u2502   \u2502   \u251c\u2500\u2500 test_document_workflow.py        # Document upload \u2192 extraction \u2192 validation\n\u2502   \u2502   \u2514\u2500\u2500 test_calculation_accuracy.py     # Verify emission calculations\n\u2502   \u2514\u2500\u2500 postman/\n\u2502       \u2514\u2500\u2500 sustaina-api.postman_collection.json\n\u2502\n\u251c\u2500\u2500 .codemachine/                            # CodeMachine orchestration\n\u2502   \u251c\u2500\u2500 inputs/\n\u2502   \u2502   \u2514\u2500\u2500 specifications.md                # Source requirements (187 pages)\n\u2502   \u251c\u2500\u2500 artifacts/\n\u2502   \u2502   \u251c\u2500\u2500 architecture/                    # Generated blueprints\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 ... (6 documents)\n\u2502   \u2502   \u251c\u2500\u2500 plan/                            # Iteration plans\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 ... (7 documents)\n\u2502   \u2502   \u2514\u2500\u2500 tasks/                           # Task specifications\n\u2502   \u2502       \u2514\u2500\u2500 ... (5 JSON files, 39 tasks)\n\u2502   \u251c\u2500\u2500 prompts/\n\u2502   \u2502   \u251c\u2500\u2500 context.md\n\u2502   \u2502   \u251c\u2500\u2500 plan_fallback.md\n\u2502   \u2502   \u251c\u2500\u2500 task_fallback.md\n\u2502   \u2502   \u2514\u2500\u2500 code_fallback.md\n\u2502   \u251c\u2500\u2500 agents/\n\u2502   \u2502   \u2514\u2500\u2500 agents-config.json\n\u2502   \u2514\u2500\u2500 template.json\n\u2502\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 .dockerignore\n\u251c\u2500\u2500 .pre-commit-config.yaml                  # Pre-commit hooks (linters, formatters)\n\u251c\u2500\u2500 .eslintrc.js\n\u251c\u2500\u2500 .prettierrc\n\u251c\u2500\u2500 package.json                             # Root workspace (monorepo)\n\u251c\u2500\u2500 package-lock.json\n\u251c\u2500\u2500 openapitools.json                        # OpenAPI Generator config\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 CONTRIBUTING.md\n\u2514\u2500\u2500 LICENSE\n</code></pre> <p>Directory Statistics: - Total Directories: 147 - Total Files: 482 - Lines of Code: 60,008 (excluding dependencies)</p> <p>Code Breakdown by Language: <pre><code>Language                 Files        Code Lines\nJSON                       44          21,155\nPython                    118          11,915\nMarkdown                   42           8,910\nTypeScript                 99           6,236\nYAML                       83           5,716\nHCL (Terraform)            19           1,693\nPlantUML                    8             840\nJavaScript                 22             936\nShell Scripts               9             879\nHTML                        7             938\nSQL                         5             473\nDockerfile                  7             139\nOther                      19             178\n</code></pre></p>"},{"location":"case-studies/sustaina/#7-key-implementation-patterns","title":"7. Key Implementation Patterns","text":""},{"location":"case-studies/sustaina/#71-multi-tenancy-pattern","title":"7.1 Multi-Tenancy Pattern","text":"<p>Row-Level Security with Partition Key: <pre><code># shared/python-common/sustaina_common/models.py\nfrom sqlalchemy import Column, UUID, TIMESTAMP\nfrom sqlalchemy.ext.declarative import declarative_base\n\nBase = declarative_base()\n\nclass BaseModel(Base):\n    __abstract__ = True\n\n    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n    company_id = Column(UUID(as_uuid=True), nullable=False, index=True)  # Partition key\n    created_at = Column(TIMESTAMP, default=func.now())\n    updated_at = Column(TIMESTAMP, default=func.now(), onupdate=func.now())\n</code></pre></p> <p>Automatic Filtering: <pre><code># services/compliance-service/src/api/checklists.py\nfrom fastapi import Depends, HTTPException\nfrom shared.python_common.auth import get_current_user\n\n@router.get(\"/checklists\")\ndef get_checklists(\n    user: User = Depends(get_current_user),\n    db: Session = Depends(get_db)\n):\n    # Automatically filter by user's company_id\n    checklists = db.query(ComplianceChecklist).filter(\n        ComplianceChecklist.company_id == user.company_id\n    ).all()\n    return checklists\n</code></pre></p>"},{"location":"case-studies/sustaina/#72-event-driven-workflow-pattern","title":"7.2 Event-Driven Workflow Pattern","text":"<p>Document Processing Workflow: <pre><code># services/document-processing-service/src/workers/ocr_worker.py\nimport boto3\n\nsqs = boto3.client('sqs')\nsns = boto3.client('sns')\n\ndef process_document_upload_event(event):\n    \"\"\"\n    Consumes: DocumentUploaded event\n    Publishes: DocumentTextExtracted event\n    \"\"\"\n    document_id = event['document_id']\n    s3_key = event['s3_key']\n\n    # Step 1: Download from S3\n    document_bytes = s3_client.get_object(Bucket='sustaina-documents', Key=s3_key)['Body'].read()\n\n    # Step 2: OCR\n    if s3_key.endswith('.pdf'):\n        text = extract_text_from_pdf(document_bytes)  # PyPDF2\n    else:\n        text = extract_text_from_image(document_bytes)  # PyTesseract\n\n    # Step 3: Store extracted text\n    db.query(Document).filter(Document.id == document_id).update({'extracted_text': text})\n    db.commit()\n\n    # Step 4: Publish event for LLM extraction\n    sns.publish(\n        TopicArn='arn:aws:sns:eu-central-1:123456789:document-text-extracted',\n        Message=json.dumps({'document_id': document_id, 'text': text})\n    )\n</code></pre></p>"},{"location":"case-studies/sustaina/#73-ai-extraction-pattern-with-confidence-scoring","title":"7.3 AI Extraction Pattern with Confidence Scoring","text":"<p>LLM Pipeline: <pre><code># services/document-processing-service/src/core/llm_pipeline.py\nfrom langchain import PromptTemplate, LLMChain\nfrom langchain.llms import OpenAI\n\ndef extract_invoice_fields(text: str) -&gt; dict:\n    \"\"\"\n    Extract structured fields from invoice text using GPT-4\n    Returns: {fields: dict, confidence_scores: dict}\n    \"\"\"\n    prompt = PromptTemplate(\n        input_variables=[\"text\"],\n        template=\"\"\"\n        Extract the following fields from this invoice:\n        - supplier_name\n        - supplier_location (country)\n        - total_amount (numeric value only)\n        - invoice_date (ISO 8601 format)\n        - line_items (array of {description, quantity, unit_price})\n\n        Respond ONLY with valid JSON. For each field, provide a confidence score (0-1).\n\n        Invoice text:\n        {text}\n\n        JSON:\n        \"\"\"\n    )\n\n    llm = OpenAI(model=\"gpt-4\", temperature=0)  # Low temp for consistency\n    chain = LLMChain(llm=llm, prompt=prompt)\n\n    result = chain.run(text=text)\n    parsed = json.loads(result)\n\n    # Separate fields and confidence scores\n    fields = {k: v['value'] for k, v in parsed.items()}\n    confidence_scores = {k: v['confidence'] for k, v in parsed.items()}\n\n    return fields, confidence_scores\n</code></pre></p> <p>Human-in-the-Loop for Low Confidence: <pre><code># services/document-processing-service/src/core/validator.py\ndef validate_extraction(document_id: str, fields: dict, confidence_scores: dict):\n    \"\"\"\n    Flag extractions with low confidence for human review\n    \"\"\"\n    CONFIDENCE_THRESHOLD = 0.8\n\n    low_confidence_fields = [\n        field for field, score in confidence_scores.items()\n        if score &lt; CONFIDENCE_THRESHOLD\n    ]\n\n    if low_confidence_fields:\n        # Create review task\n        db.add(ReviewTask(\n            document_id=document_id,\n            status='pending_review',\n            flagged_fields=low_confidence_fields,\n            message=f\"Low confidence on: {', '.join(low_confidence_fields)}\"\n        ))\n        db.commit()\n\n        # Notify admin\n        sns.publish(\n            TopicArn='arn:aws:sns:eu-central-1:123456789:admin-review-required',\n            Message=f\"Document {document_id} requires human review\"\n        )\n</code></pre></p>"},{"location":"case-studies/sustaina/#74-carbon-calculation-pattern","title":"7.4 Carbon Calculation Pattern","text":"<p>GHG Protocol Implementation: <pre><code># services/carbon-accounting-service/src/core/ghg_calculator.py\nfrom decimal import Decimal\n\nclass GHGCalculator:\n    def calculate_product_emissions(self, product_id: UUID) -&gt; EmissionCalculation:\n        \"\"\"\n        Calculate Scope 1-3 emissions for a product\n        \"\"\"\n        # Fetch product with suppliers\n        product = db.query(Product).filter(Product.id == product_id).first()\n        suppliers = product.suppliers  # Many-to-many relationship\n\n        # Scope 1: Direct manufacturing emissions\n        scope1 = self._calculate_scope1(product)\n\n        # Scope 2: Purchased energy emissions\n        scope2 = self._calculate_scope2(product)\n\n        # Scope 3: Supply chain emissions (recursive)\n        scope3 = self._calculate_scope3(product, suppliers)\n\n        total_co2e = scope1 + scope2 + scope3\n\n        # Data quality score (higher if using supplier-specific data vs defaults)\n        quality_score = self._calculate_data_quality(suppliers)\n\n        # Save calculation\n        calculation = EmissionCalculation(\n            product_id=product_id,\n            scope1_co2e=scope1,\n            scope2_co2e=scope2,\n            scope3_co2e=scope3,\n            total_co2e=total_co2e,\n            data_quality_score=quality_score,\n            calculation_date=datetime.utcnow()\n        )\n        db.add(calculation)\n        db.commit()\n\n        return calculation\n\n    def _calculate_scope3(self, product: Product, suppliers: List[Supplier]) -&gt; Decimal:\n        \"\"\"\n        Aggregate supplier emissions (multi-tier supply chain)\n        \"\"\"\n        scope3_total = Decimal(0)\n\n        for supplier in suppliers:\n            # Get product-supplier link (quantity used)\n            link = db.query(ProductSupplier).filter(\n                ProductSupplier.product_id == product.id,\n                ProductSupplier.supplier_id == supplier.id\n            ).first()\n\n            quantity = link.quantity\n\n            # Lookup emission factor\n            emission_factor = self._get_emission_factor(\n                region=supplier.location,\n                sector=supplier.industry_sector,\n                activity=link.activity  # e.g., \"cement production\"\n            )\n\n            # Calculate emissions for this supplier\n            supplier_emissions = quantity * emission_factor.co2e_per_unit\n\n            scope3_total += supplier_emissions\n\n        return scope3_total\n\n    def _get_emission_factor(self, region: str, sector: str, activity: str) -&gt; EmissionFactor:\n        \"\"\"\n        Fetch emission factor with Redis caching\n        \"\"\"\n        cache_key = f\"ef:{region}:{sector}:{activity}\"\n\n        # Try cache first\n        cached = redis.get(cache_key)\n        if cached:\n            return EmissionFactor(**json.loads(cached))\n\n        # Query database\n        factor = db.query(EmissionFactor).filter(\n            EmissionFactor.region == region,\n            EmissionFactor.industry_sector == sector,\n            EmissionFactor.activity == activity\n        ).first()\n\n        if not factor:\n            # Substitution logic: fallback to default factor\n            factor = self._get_default_emission_factor(sector, activity)\n\n        # Cache for 30 days\n        redis.setex(cache_key, 30 * 24 * 3600, json.dumps(factor.to_dict()))\n\n        return factor\n</code></pre></p>"},{"location":"case-studies/sustaina/#75-infrastructure-as-code-pattern","title":"7.5 Infrastructure as Code Pattern","text":"<p>Terraform Module for S3 + CloudFront: <pre><code># infrastructure/terraform/modules/s3-web-hosting/main.tf\nresource \"aws_s3_bucket\" \"web_app\" {\n  bucket = \"sustaina-web-app-${var.environment}\"\n\n  tags = {\n    Name        = \"Sustaina Web App\"\n    Environment = var.environment\n  }\n}\n\nresource \"aws_s3_bucket_public_access_block\" \"web_app\" {\n  bucket = aws_s3_bucket.web_app.id\n\n  block_public_acls       = true  # Security: No public ACLs\n  block_public_policy     = true\n  ignore_public_acls      = true\n  restrict_public_buckets = true\n}\n\nresource \"aws_s3_bucket_website_configuration\" \"web_app\" {\n  bucket = aws_s3_bucket.web_app.id\n\n  index_document {\n    suffix = \"index.html\"\n  }\n\n  error_document {\n    key = \"index.html\"  # SPA routing\n  }\n}\n\n# CloudFront Origin Access Control (OAC)\nresource \"aws_cloudfront_origin_access_control\" \"web_app\" {\n  name                              = \"sustaina-web-app-${var.environment}\"\n  origin_access_control_origin_type = \"s3\"\n  signing_behavior                  = \"always\"\n  signing_protocol                  = \"sigv4\"\n}\n\n# ACM Certificate (must be in us-east-1 for CloudFront)\nresource \"aws_acm_certificate\" \"web_app\" {\n  provider          = aws.us_east_1  # Alias provider\n  domain_name       = var.domain_name\n  validation_method = \"DNS\"\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n\n# CloudFront Distribution\nresource \"aws_cloudfront_distribution\" \"web_app\" {\n  enabled             = true\n  is_ipv6_enabled     = true\n  default_root_object = \"index.html\"\n  aliases             = [var.domain_name]\n\n  origin {\n    domain_name              = aws_s3_bucket.web_app.bucket_regional_domain_name\n    origin_id                = \"S3-${aws_s3_bucket.web_app.id}\"\n    origin_access_control_id = aws_cloudfront_origin_access_control.web_app.id\n  }\n\n  default_cache_behavior {\n    allowed_methods  = [\"GET\", \"HEAD\", \"OPTIONS\"]\n    cached_methods   = [\"GET\", \"HEAD\"]\n    target_origin_id = \"S3-${aws_s3_bucket.web_app.id}\"\n\n    forwarded_values {\n      query_string = false\n      cookies {\n        forward = \"none\"\n      }\n    }\n\n    viewer_protocol_policy = \"redirect-to-https\"\n    min_ttl                = 0\n    default_ttl            = 0      # index.html not cached\n    max_ttl                = 0\n  }\n\n  # Cache static assets (JS, CSS) for 1 year\n  ordered_cache_behavior {\n    path_pattern     = \"/assets/*\"\n    allowed_methods  = [\"GET\", \"HEAD\"]\n    cached_methods   = [\"GET\", \"HEAD\"]\n    target_origin_id = \"S3-${aws_s3_bucket.web_app.id}\"\n\n    forwarded_values {\n      query_string = false\n      cookies {\n        forward = \"none\"\n      }\n    }\n\n    viewer_protocol_policy = \"redirect-to-https\"\n    min_ttl                = 31536000  # 1 year\n    default_ttl            = 31536000\n    max_ttl                = 31536000\n  }\n\n  viewer_certificate {\n    acm_certificate_arn      = aws_acm_certificate.web_app.arn\n    ssl_support_method       = \"sni-only\"\n    minimum_protocol_version = \"TLSv1.2_2021\"\n  }\n\n  restrictions {\n    geo_restriction {\n      restriction_type = \"none\"\n    }\n  }\n\n  logging_config {\n    bucket = aws_s3_bucket.cloudfront_logs.bucket_domain_name\n    prefix = \"web-app/\"\n  }\n}\n\n# Route 53 DNS Record\nresource \"aws_route53_record\" \"web_app\" {\n  zone_id = var.route53_zone_id\n  name    = var.domain_name\n  type    = \"A\"\n\n  alias {\n    name                   = aws_cloudfront_distribution.web_app.domain_name\n    zone_id                = aws_cloudfront_distribution.web_app.hosted_zone_id\n    evaluate_target_health = false\n  }\n}\n\n# Outputs for CI/CD\noutput \"distribution_id\" {\n  value       = aws_cloudfront_distribution.web_app.id\n  description = \"CloudFront distribution ID for cache invalidation\"\n}\n\noutput \"bucket_name\" {\n  value       = aws_s3_bucket.web_app.id\n  description = \"S3 bucket name for deployment\"\n}\n</code></pre></p>"},{"location":"case-studies/sustaina/#8-results-deliverables","title":"8. Results &amp; Deliverables","text":""},{"location":"case-studies/sustaina/#81-completed-deliverables","title":"8.1 Completed Deliverables","text":"<p>Infrastructure &amp; DevOps: - \u2705 5 Terraform modules (VPC, EKS, RDS, ElastiCache, S3-Web-Hosting) - \u2705 7 Helm charts (7 microservices) - \u2705 6 ArgoCD application definitions - \u2705 4 GitHub Actions workflows (CI backend, CI frontend, CD staging, CD web-app) - \u2705 Multi-region deployment (EU-Central-1, ME-South-1) - \u2705 Blue-green deployment infrastructure</p> <p>Backend Services: - \u2705 7 microservices (Compliance, Carbon Accounting, Document Processing, Risk Assessment, Supply Chain, ESG Reporting, Notification) - \u2705 42 API endpoints (RESTful, OpenAPI 3.1 documented) - \u2705 PostgreSQL schema (15 tables, 32 indexes, row-level security) - \u2705 MongoDB regulatory framework schemas (CBAM, ISO 14064, GHG Protocol) - \u2705 Redis caching layer (emission factors, API responses) - \u2705 SQS/SNS event-driven workflows (document processing, calculations) - \u2705 AI document processing pipeline (PyTesseract OCR + GPT-4 extraction) - \u2705 GHG Protocol carbon calculation engine (Scopes 1-3) - \u2705 CBAM report generation (PDF with standardized templates) - \u2705 Traffic-light risk scoring algorithm</p> <p>Frontend: - \u2705 React 18 web application (TypeScript) - \u2705 5 feature modules (Compliance, Carbon, Documents, Risk, Auth) - \u2705 15+ reusable UI components (Button, Card, Modal, Table, etc.) - \u2705 React Query for server state management - \u2705 Tailwind CSS design system - \u2705 i18next internationalization (English, Arabic) - \u2705 Deployed to S3 + CloudFront CDN</p> <p>Testing &amp; Quality: - \u2705 Unit tests (&gt;80% coverage across services) - \u2705 Integration tests (cross-service workflows) - \u2705 Playwright E2E tests (compliance workflow, carbon calculation, CBAM report) - \u2705 Postman collection (45 API requests with examples) - \u2705 Load testing reports (k6: 1000 concurrent users, &lt;60s response time) - \u2705 OWASP ZAP security scan (0 high-severity vulnerabilities)</p> <p>Documentation: - \u2705 6 architecture blueprint documents (187 pages) - \u2705 7 PlantUML diagrams (Context, Container, Component, ERD, 2 Sequence, Deployment) - \u2705 6 OpenAPI 3.1 specifications (5 services + consolidated) - \u2705 3 Architectural Decision Records (ADRs) - \u2705 4 operational runbooks (deploy, disaster recovery, incident response) - \u2705 Auto-generated API documentation (Swagger UI, Redoc)</p> <p>Data &amp; Configuration: - \u2705 30+ emission factors (DEFRA, EPA datasets) - \u2705 3 regulatory framework definitions (CBAM, ISO 14064, GHG Protocol) - \u2705 Sample test data (5 SME companies, 20 products, 50 suppliers)</p>"},{"location":"case-studies/sustaina/#82-visual-deliverables","title":"8.2 Visual Deliverables","text":"<p>C4 Architecture Diagrams: 1. System Context Diagram: Shows Sustaina platform boundary with external actors (SME users, auditors, supply chain managers) and systems (LLM providers, emission databases, Auth0, email service) 2. Container Diagram: Illustrates 7 microservices, API Gateway, Web App, 4 databases (PostgreSQL, MongoDB, Redis, S3), message queue (SQS/SNS), search engine (Elasticsearch) 3. Component Diagram (Document Processing Service): Details OCR Engine, LLM Pipeline, Validation Engine, Evidence Repository, Event Publisher 4. Deployment Diagram: AWS infrastructure across 3 availability zones (VPC, subnets, ALB, EKS nodes, RDS Multi-AZ, ElastiCache, S3, SQS)</p> <p>Data Model: - ERD: 15 entities with relationships (Company \u2192 Users, Products \u2192 Suppliers, Documents \u2192 Extractions, Checklists \u2192 Items)</p> <p>Workflow Diagrams: 1. Document Upload Sequence: User \u2192 Upload \u2192 OCR \u2192 LLM Extraction \u2192 Validation \u2192 Risk Update \u2192 Notification 2. CBAM Calculation Sequence: User \u2192 Calculation Request \u2192 Supplier Fetch \u2192 Emission Factor Lookup \u2192 Calculate \u2192 Report Generation \u2192 Notification</p>"},{"location":"case-studies/sustaina/#83-code-quality-metrics","title":"8.3 Code Quality Metrics","text":"Metric Target Achieved Test Coverage &gt;80% 84% (Backend), 78% (Frontend) API Response Time &lt;60s (calculations) 42s average (100 suppliers) AI Extraction Accuracy &gt;90% (structured), &gt;80% (semi-structured) 94% (invoices), 83% (scanned PDFs) Uptime (Staging) 99.5% 99.7% (30-day average) Build Time (CI) &lt;10 minutes 7.5 minutes (parallel jobs) Docker Image Size &lt;500MB per service 280MB average (multi-stage builds) OpenAPI Compliance 100% endpoints documented 100% (42/42 endpoints) Security Vulnerabilities 0 critical/high 0 high, 2 medium (false positives)"},{"location":"case-studies/sustaina/#9-technical-metrics","title":"9. Technical Metrics","text":""},{"location":"case-studies/sustaina/#91-development-velocity-automation-metrics","title":"9.1 Development Velocity &amp; Automation Metrics","text":"<p>Total Project Timeline: 10 weeks (Fully automated development)</p> <p>Phase-by-Phase Breakdown:</p> Phase Time Investment Key Deliverables Architecture Planning 30 minutes System architecture, C4 diagrams, ERDs, technical design decisions Service Implementation 5 hours 7 microservices with 42 API endpoints, 60,008 lines of code across 482 files Integration &amp; Testing 2 hours Automated validation, unit tests, integration tests, E2E workflows Deployment Setup 30 minutes Terraform modules, Helm charts, CI/CD pipelines, runtime automation scripts Total Active Development ~8 hours Complete production-ready platform <p>Development Efficiency: - Efficiency Gain: 25-37\u00d7 faster than traditional development - Code Consistency: Unified architecture and patterns across all 7 microservices - Quality Control: Built-in validation at each step with automated sanity checks - Context Retention: Full project context maintained with cross-service awareness throughout development</p> <p>Code Generation Metrics: - Lines of Code Generated: 60,008 (482 files) - Automated Code Distribution:   - JSON configurations: 21,155 lines   - Python services: 11,915 lines   - TypeScript/JavaScript: 7,172 lines   - Infrastructure (YAML + HCL): 7,409 lines   - Documentation: 8,910 lines</p>"},{"location":"case-studies/sustaina/#92-infrastructure-metrics","title":"9.2 Infrastructure Metrics","text":"<p>AWS Resources Provisioned (Staging Environment): - Compute:   - 1 EKS cluster (Kubernetes 1.28)   - 6 EC2 instances (t3.large) across 3 availability zones   - Auto-scaling group (min 2, max 10 nodes) - Databases:   - 1 RDS PostgreSQL 15 (db.r6g.xlarge, Multi-AZ)   - 1 ElastiCache Redis 7 cluster (2 nodes, cross-AZ replication)   - 1 MongoDB Atlas cluster (M10 tier, 3-node replica set) - Storage:   - 3 S3 buckets (documents, backups, CloudFront logs)   - Total storage: 45 GB (documents: 30 GB, backups: 12 GB, logs: 3 GB) - Networking:   - 1 VPC (10.0.0.0/16)   - 6 subnets (3 public, 3 private)   - 2 NAT Gateways   - 1 Application Load Balancer   - 1 CloudFront distribution - Message Queue:   - 5 SQS queues (document-processing, calculation-requests, notifications, risk-updates, dead-letter)   - 3 SNS topics (document-events, calculation-events, admin-alerts)</p>"},{"location":"case-studies/sustaina/#93-performance-benchmarks","title":"9.3 Performance Benchmarks","text":"<p>API Response Times (k6 Load Testing): - Checklist Generation: 1.2s average (500 concurrent users) - Product Emission Calculation: 42s average (100 suppliers), 18s (20 suppliers) - Document Upload (Presigned URL): 0.3s - Document Extraction (Async): 8-12s (OCR + LLM pipeline) - Risk Score Retrieval: 0.8s (with Redis cache), 2.4s (cache miss)</p> <p>Database Query Performance: - Emission Factor Lookup: 12ms (indexed query on region + sector + activity) - Supplier List (Pagination): 35ms (1000 suppliers, cursor-based pagination) - Audit Log Write: 8ms (append-only table, no indexes on write path) - MongoDB Framework Query: 18ms (indexed on jurisdiction)</p> <p>AI Processing Performance: - OCR (PyTesseract): 3-5s per scanned PDF page - GPT-4 Extraction: 4-8s per document (latency depends on OpenAI API) - Validation Engine: 0.5s (ruleset matching against 50 regulatory requirements)</p>"},{"location":"case-studies/sustaina/#94-scalability-metrics","title":"9.4 Scalability Metrics","text":"<p>Horizontal Pod Autoscaling (HPA) Configuration: - Compliance Service: Min 2, Max 8 replicas (CPU threshold: 70%) - Carbon Accounting Service: Min 2, Max 10 replicas (CPU threshold: 75%, high compute for calculations) - Document Processing Service: Min 3, Max 12 replicas (Memory threshold: 80%, high memory for OCR/LLM) - Risk Assessment Service: Min 2, Max 6 replicas - Supply Chain Service: Min 2, Max 6 replicas - Notification Service: Min 2, Max 5 replicas</p> <p>Concurrent User Testing: - Test Scenario: 1000 concurrent users performing mixed operations (checklist retrieval, document uploads, calculations) - Result: Average response time: 1.8s, 99th percentile: 5.2s, 0.02% error rate (all timeouts, no crashes)</p>"},{"location":"case-studies/sustaina/#conclusion","title":"Conclusion","text":"<p>The Sustaina ESG Compliance Platform represents a successful demonstration of AI-orchestrated software development at enterprise scale. CodeMachine's multi-agent architecture transformed a 187-page specification into a production-ready system with:</p> <ul> <li>7 microservices handling complex regulatory logic, AI document processing, and carbon accounting</li> <li>Multi-database architecture (PostgreSQL, MongoDB, Redis, Elasticsearch) optimized for different data patterns</li> <li>Cloud-native infrastructure (AWS EKS, RDS, S3, CloudFront) with blue-green deployment</li> <li>Comprehensive testing (unit, integration, E2E) achieving 84% backend and 78% frontend coverage, with key calculation SLAs of 42s (against a 60s target)</li> <li>Full CI/CD automation (GitHub Actions, ArgoCD) enabling daily deployments to staging</li> </ul> <p>Key Innovations: 1. Hierarchical Agent Orchestration: 48 specialized agents coordinated through bidirectional communication, reducing development time by an estimated 75% compared to manual implementation 2. Context-Aware Code Generation: Dynamic injection of architecture blueprints and existing code patterns ensured consistency and reduced hallucinations 3. Verification-Driven Quality: Automated validation loops (OpenAPI, SQL, TypeScript compilation) caught 87% of errors pre-review 4. Artifact-First Development: PlantUML diagrams and OpenAPI specs served as executable documentation, staying synchronized with code</p> <p>Impact for SMEs: - Democratized Compliance: Complex CBAM, ESRS, ISO regulations distilled into clear checklists and traffic-light risk indicators - Reduced Compliance Costs: Estimated 60% cost reduction vs manual consultants (\u20ac5,000/year vs \u20ac12,000-15,000) - Faster Market Access: CBAM reports generated in minutes vs weeks of manual calculation - Audit Readiness: AI-verified documentation provides defensible compliance evidence</p> <p>CodeMachine has proven that specification-to-code orchestration can deliver enterprise-grade systems when: - Specifications are detailed and structured (architecture blueprints, acceptance criteria) - Agents are specialized by domain (database, backend, frontend, DevOps) - Verification loops validate artifacts continuously - Human oversight focuses on strategic decisions rather than boilerplate code</p> <p>As Sustaina scales to serve thousands of SMEs across the MENA region, the CodeMachine-generated foundation provides a robust, maintainable, and extensible platform for continuous evolution of ESG compliance requirements.</p>"}]}